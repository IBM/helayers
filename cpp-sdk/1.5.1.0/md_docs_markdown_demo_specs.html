<!-- HTML header for doxygen 1.8.8-->
<!DOCTYPE html
    PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <!-- For Mobile Devices -->
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8" />
    <meta name="generator" content="Doxygen 1.8.17" />
    <title>HElayers SDK: Demo specification</title>
    <!--<link href="tabs.css" rel="stylesheet" type="text/css"/>-->
    <link href="doxygen.css" rel="stylesheet" type="text/css" />
    <link href="customdoxygen.css" rel="stylesheet" type="text/css"/>
    <link href='https://fonts.googleapis.com/css?family=Roboto+Slab' rel='stylesheet' type='text/css'>
    <link
        href="https://fonts.googleapis.com/css2?family=IBM+Plex+Sans:ital,wght@0,100;1,700&family=Merriweather&family=Merriweather+Sans&family=Open+Sans&family=Poppins:ital@1&family=Roboto:ital,wght@0,400;1,300;1,900&display=swap"
        rel="stylesheet">
    <script type="module" src="https://1.www.s81c.com/common/carbon/web-components/tag/latest/ui-shell.min.js"></script>
</head>
<body style="font-family: 'Merriweather', serif;">
    <nav class="navbar navbar-default" role="navigation">
        <div class="container">
            <div class="navbar-header">
                <a class="navbar-brand">HElayers SDK 1.5.1.0</a>
            </div>
        </div>
    </nav>
    <div id="top">
        <bx-header aria-label="IBM Platform Name">
            <bx-header-menu-button button-label-active="Close menu" button-label-inactive="Open menu">
            </bx-header-menu-button>
            <bx-header-name href="index.html" prefix="IBM">HElayers</bx-header-name>
            <bx-header-nav menu-bar-label="IBM HElayers">
                <bx-header-nav-item href="index.html">Overview
                </bx-header-nav-item>
                <bx-header-menu menu-label="Namespaces" trigger-content="Namespaces">
                    <bx-header-menu-item href="namespaces.html">Namespace List
                    </bx-header-menu-item>
                    <bx-header-menu menu-label="Namespace Members" trigger-content="Namespace  Members">
                        <bx-header-menu-item href="namespacemembers.html">All
                        </bx-header-menu-item>
                        <bx-header-menu-item href="namespacemembers_func.html">Functions
                        </bx-header-menu-item>
                        <bx-header-menu-item href="namespacemembers_type.html">Typedefs
                        </bx-header-menu-item>
                        <bx-header-menu-item href="namespacemembers_enum.html">Enumerations
                        </bx-header-menu-item>
                        <bx-header-menu-item href="namespacemembers_eval.html">Enumerator
                        </bx-header-menu-item>
                    </bx-header-menu>
                </bx-header-menu>
                <bx-header-menu menu-label="Classes" trigger-content="Classes">
                    <bx-header-menu-item href="annotated.html">Class List
                    </bx-header-menu-item>
                    <bx-header-menu-item href="classes.html">Class Index
                    </bx-header-menu-item>
                    <bx-header-menu-item href="inherits.html">Class Hierarchy
                    </bx-header-menu-item>
                    <bx-header-menu menu-label="Class Members" trigger-content="Class Members">
                        <bx-header-menu-item href="functions.html">All
                        </bx-header-menu-item>
                        <bx-header-menu-item href="functions_func.html">Functions
                        </bx-header-menu-item>
                        <bx-header-menu-item href="functions_type.html">Variables
                        </bx-header-menu-item>
                        <bx-header-menu-item href="functions_type.html">Typedefs
                        </bx-header-menu-item>
                        <bx-header-menu-item href="functions_enum.html">Enumerations
                        </bx-header-menu-item>
                    </bx-header-menu>
                </bx-header-menu>
                <bx-header-menu menu-label="Files" trigger-content="Files">
                    <bx-header-menu-item href="files.html">File List</bx-header-menu-item>
                </bx-header-menu>
            </bx-header-nav>
        </bx-header>
        <!-- do not remove this div, it is closed by doxygen! -->
        <!-- end header part --><!-- Generated by Doxygen 1.8.17 -->
</div><!-- top -->
<div class="PageDoc"><div class="header">
  <div class="headertitle">
<div class="title">Demo specification </div>  </div>
</div><!--header-->
<div class="contents">
<div class="textblock"><p>Performance stats are reported on these machines:</p><ol type="1">
<li>Intel(R) Xeon(R) CPU E5-2699 v4 @ 2.20GHz, 88 CPU, 744GB RAM</li>
</ol>
<h2><a class="anchor" id="autotoc_md1"></a>
01 FHE basics</h2>
<p>An overview of APIs.</p>
<h2><a class="anchor" id="autotoc_md2"></a>
02 Credit card fraud detection</h2>
<ul>
<li>Model type: Neural network</li>
<li>Network architecture: 3 FC layers of sizes 20, 5, 1, with square activations.</li>
<li>Input: a vector of 29 elements.</li>
<li>Encrypted model weights.</li>
<li>Time &amp; memory performance (Machine 1):<ul>
<li>When optimized for latency: 0.24 seconds per sample, memory 0.6 GB.</li>
<li>When optimized for throughput: 0.51 seconds per batch of 8192 samples, memory 6.2 GB.</li>
<li>Intermediate settings: 0.36 seconds per batch of 1024 samples, memory 1.5 GB.</li>
</ul>
</li>
<li>FHE scheme: SEAL CKKS, security 192, depth 6, poly degree 2^14.<ul>
<li>Evaluation keys size: 46 MB.</li>
</ul>
</li>
<li>Time performance in the clear: 0.042 seconds for 8192 samples, 0.013 seconds for 1024 samples, 0.009 seconds for 1 sample.</li>
<li>FHE NeuralNet implementation inherits from HeModel.</li>
</ul>
<h2><a class="anchor" id="autotoc_md3"></a>
03 Credit card fraud detection with logistic regression</h2>
<ul>
<li>Model type: logistic regression.</li>
<li>Input: a vector of 29 elements.</li>
<li>Time &amp; memory performance (Machine 1):<ul>
<li>When optimized for throughput: 0.35 seconds per batch of 8192 samples, memory 900 MB.</li>
<li>Intermediate settings: 0.25 seconds per batch of 1024 samples, memory 608 MB.</li>
</ul>
</li>
<li>FHE scheme: HEaaN CKKS, security 128, depth 7, poly degree 2^14.</li>
<li>Time performance in the clear: 0.0033 seconds for 8192 samples, 0.0021 seconds for 1024 samples.</li>
<li>FHE LogisticRegression implementation inherits form HeModel.</li>
</ul>
<h2><a class="anchor" id="autotoc_md4"></a>
04 Text classification</h2>
<ul>
<li>Model type: Neural network</li>
<li>Network architecture: 2 FC layers of sizes 300, 4, with poly activation (degree 2) in between.</li>
<li>Input: a vector of 3000 elements.</li>
<li>Encrypted model weights.</li>
<li>Time &amp; memory performance (Machine 1):<ul>
<li>When optimized for latency: 0.126 seconds per sample, memory 1.2 GB.</li>
<li>Intermediate setting 1: 0.639 seconds per batch of 16 samples, memory 9.2 GB.</li>
<li>Intermediate setting 2: 7.69 seconds per batch of 256 samples, memory 119.3 GB.</li>
</ul>
</li>
<li>FHE scheme: SEAL CKKS, security 128, depth 3, poly degree 2^13.<ul>
<li>Evaluation keys size: 30MB.</li>
</ul>
</li>
<li>Time performance in the clear: 2.7 seconds for 256 samples, 0.28 seconds for 16 samples, 0.025 seconds for 1 sample.</li>
<li>FHE NeuralNet implementation inherits from HeModel.</li>
</ul>
<h2><a class="anchor" id="autotoc_md5"></a>
05 Deep Neural Networks - AlexNet</h2>
<ul>
<li>Model type: Neural network</li>
<li>Network architecture: 5 convolutional layers followed by 3 fully-connected layers.</li>
<li>Input: an image of size 224x224x3.</li>
<li>Non-encrypted model weights, lazy encoding.</li>
<li>Time &amp; memory performance (Machine 1):<ul>
<li>When optimized for latency: 3:28 minutes per sample, memory 76.1 GB.</li>
</ul>
</li>
<li>FHE scheme: HEaaN CKKS, security 128, depth 20, poly degree 2^15.<ul>
<li>Evaluation keys size: 6.3 GB.</li>
</ul>
</li>
<li>Time performance in the clear: 3.3 seconds for 1 sample.</li>
<li>FHE NeuralNet implementaiton inherits from HeModel.</li>
</ul>
<h2><a class="anchor" id="autotoc_md6"></a>
05 Deep Neural Networks - SqueezeNet</h2>
<ul>
<li>Model type: Neural network</li>
<li>Network architecture: 26 convolutional layers.</li>
<li>Input: an image of size 224x224x3.</li>
<li>Non-encrypted model weights, lazy encoding.</li>
<li>Time &amp; memory performance (Machine 1):<ul>
<li>When optimized for latency: 8:45 minutes per sample, memory 100.1 GB, requires 304 bootstraps.</li>
</ul>
</li>
<li>FHE scheme: HEaaN CKKS, security 128, depth 12, poly degree 2^16.</li>
<li>Time performance in the clear: 5.4 seconds for 1 sample.</li>
</ul>
<h2><a class="anchor" id="autotoc_md7"></a>
05 Deep Neural Networks - ResNet-18</h2>
<ul>
<li>Model type: Neural network</li>
<li>Network architecture: 20 convolutional layers.</li>
<li>Input: an image of size 224x224x3.</li>
<li>Non-encrypted model weights, lazy encoding.</li>
<li>Time &amp; memory performance (Machine 1):<ul>
<li>When optimized for latency: 16:02 minutes per sample, memory 150.7 GB, requires 512 bootstraps.</li>
</ul>
</li>
<li>FHE scheme: HEaaN CKKS, security 128, depth 12, poly degree 2^16.</li>
<li>Time performance in the clear: 13.8 seconds for 1 sample.</li>
</ul>
<h2><a class="anchor" id="autotoc_md8"></a>
05 Deep Neural Networks - AlexNet with no padding</h2>
<ul>
<li>Model type: Neural network</li>
<li>Network architecture:<ul>
<li>Conv2D, 64 filters, kernel 11x11, strides 4x4, valid padding.</li>
<li>Square activation.</li>
<li>Average pooling, pool 3x3, strides 2x2, valid padding.</li>
<li>Conv2D, 192 filters, kernel 5x5, strides 1x1, valid padding.</li>
<li>Square activation.</li>
<li>Average pooling, pool 3x3, strides 2x2, valid padding.</li>
<li>Conv2D, 384 filters, kernel 3x3, strides 1x1, valid padding.</li>
<li>Square activation.</li>
<li>Conv2D, 256 filters, kernel 3x3, strides 1x1, valid padding.</li>
<li>Square activation.</li>
<li>Conv2D, 256 filters, kernel 3x3, strides 1x1, valid padding.</li>
<li>Square activation.</li>
<li>Average pooling, pool 3x3, strides 2x2, valid padding.</li>
<li>Flatten.</li>
<li>FC of size 4096.</li>
<li>Square activation.</li>
<li>FC of size 4096.</li>
<li>Square activation.</li>
<li>FC of size 3.</li>
</ul>
</li>
<li>Input: an image of size 224x224x3.</li>
<li>Time &amp; memory performance (Machine 1, non-encrypted model weights):<ul>
<li>When optimized for latency: 2:59 minutes per sample, memory 142.6 GB.</li>
<li>Intermediate setting 1: 4:19 minutes per batch of 2 samples, memory 217.2 GB.</li>
<li>Intermediate setting 2: 7:40 minutes per batch of 4 samples, memory 342.2 GB.</li>
<li>Intermediate setting 3: 12:34 minutes per batch of 8 samples, memory 591.3 GB.</li>
</ul>
</li>
<li>Time &amp; memory performance (Machine 1, encrypted model weights):<ul>
<li>When optimized for latency: 4:21 minutes per sample, memory 235.6 GB.</li>
<li>Intermediate setting 1: 6:51 minutes per batch of 2 samples, memory 397.1 GB.</li>
</ul>
</li>
<li>FHE scheme: SEAL CKKS, security 128, depth 18, poly degree 2^15.</li>
<li>Time performance in the clear: 41.8 seconds for 8 samples, 22 seconds for 4 samples, 11.1 seconds for 2 samples, 5.5 seconds for 1 sample.</li>
</ul>
<h2><a class="anchor" id="autotoc_md9"></a>
06 Country / Capital Database Search</h2>
<ul>
<li>Application: privacy preserving database search.</li>
<li>Database size: 226.</li>
<li>Database of 226 rows and 2 columns.<ul>
<li>First column specifies a country and second column specifies its capital.</li>
<li>Each country and each capital is represented using an array of 32 ascii values (zero padded, 7 bit each).</li>
</ul>
</li>
<li>Input: A country name (names with up to 32 letters are supported).</li>
<li>Time &amp; memory performance (Machine 1): 5.81 sec for query processing, memory 0.15 GB.</li>
<li>FHE scheme: Helib BGV, 32 slots, 0 security, (p,m,r,l,c) = (127,128,1,1000,2).<ul>
<li>Evaluation keys size: 1 MB.</li>
</ul>
</li>
</ul>
<h2><a class="anchor" id="autotoc_md10"></a>
07 K-means nearest neighbor</h2>
<ul>
<li>Model type: K-means.</li>
<li>Model architecture: six four dimensional centroids.</li>
<li>Input: a vector of four elements.</li>
<li>Time &amp; memory performance (Machine 1):<ul>
<li>When optimized for latency: 0.014 second per sample, memory 0.3 GB.</li>
<li>When optimized for throughput: 0.055 seconds per batch of 16384 samples, memory 0.7 GB.</li>
<li>Intermediate settings: 0.04 seconds per batch of 1024 samples, memory 0.6 GB.</li>
</ul>
</li>
<li>FHE scheme: SEAL CKKS, security 128, depth 1, poly degree 2^15 when optimizing for throughput and intermediate settings and 2^13 when optimizing for latency.<ul>
<li>Evaluation keys size: 4 MB.</li>
</ul>
</li>
<li>Time performance in the clear: 0.01 seconds for 16384 samples, 0.007 seconds for 1024 samples.</li>
<li>FHE KMeans implementation inherits from HeModel.</li>
</ul>
<h2><a class="anchor" id="autotoc_md11"></a>
08 prediction of delivery status with linear regression</h2>
<ul>
<li>Model type: linear regression.</li>
<li>Input: a vector of 39 elements.</li>
<li>Time &amp; memory performance (Machine 1):<ul>
<li>When optimized for latency: 0.552 second per sample, memory 450 MB</li>
<li>When optimized for throughput: 1.01 seconds per batch of 16384 samples, memory 1.75 GB.</li>
<li>Intermediate settings: 0.530 seconds per batch of 1024 samples, memory 500 MB.</li>
</ul>
</li>
<li>FHE scheme: SEAL CKKS, security 128, depth 1, poly degree 2^13<ul>
<li>Evaluation key sizes: 4 MB</li>
</ul>
</li>
<li>Time performance in the clear: 0.002 seconds for 16384 samples, 0.003 seconds for 1024 samples.</li>
<li>FHE LinearRegression implementation inherits from HeModel.</li>
</ul>
<h2><a class="anchor" id="autotoc_md12"></a>
09 MNIST classification</h2>
<ul>
<li>Model type: Neural network</li>
<li>Network architecture: 2D Convolution layer with 5 filters, 5x5 kernel, 2x2 strdies and valid padding, 2 FC layers of sizes 100, 10, with two square activations, one before each FC.</li>
<li>Input: an image of size 29x29.</li>
<li>Encrypted model weights.</li>
<li>Time &amp; memory performance (Machine 1):<ul>
<li>When optimized for latency: 0.42 seconds per sample, memory 0.8 GB.</li>
<li>When optimized for throughput: 31.7 seconds per batch of 8192 samples, memory 349 GB.</li>
<li>Intermediate setting 1: 4.5 seconds per batch of 1024 samples, memory 61 GB.</li>
<li>Intermediate setting 2: 2.5 seconds per batch of 512 samples, memory 31 GB.</li>
<li>Intermediate setting 3: 1.5 seconds per batch of 256 samples, memory 16.5 GB.</li>
</ul>
</li>
<li>FHE scheme: SEAL CKKS, security 128, depth 6 (batch 1) or 5 (other batch sizes), poly degree 2^14.<ul>
<li>Evaluation keys size: 252 MB.</li>
</ul>
</li>
<li>Time performance in the clear: 3.274 seconds for 8192 samples, 0.862 seconds for 1024 samples, 0.024 seconds for 1 sample.</li>
<li>FHE NeuralNet implementation inherits form HeModel.</li>
</ul>
<h2><a class="anchor" id="autotoc_md13"></a>
10 Heart Disease Detection</h2>
<ul>
<li>Model type: Neural network</li>
<li>Network architecture: 2 FC layers of sizes 50, 1, with square activation in between.</li>
<li>Input: a vector of 27 elements.</li>
<li>Encrypted model weights.</li>
<li>Time &amp; memory performance (Machine 1):<ul>
<li>When optimized for latency: 0.047 seconds per sample, memory 0.15 GB.</li>
<li>When optimized for throughput: 0.203 seconds per batch of 4096 samples, memory 0.3 GB.</li>
</ul>
</li>
<li>FHE scheme: SEAL CKKS, security 128, depth 3, poly degree 2^13.<ul>
<li>Evaluation keys size: 27 MB.</li>
</ul>
</li>
<li>Time performance in the clear: 0.037 seconds for 4096 samples, 0.005 seconds for 1 sample.</li>
<li>FHE NeuralNet implementation inherits from HeModel.</li>
</ul>
<h2><a class="anchor" id="autotoc_md14"></a>
11 Tile tensors</h2>
<p>An overview of APIs.</p>
<h2><a class="anchor" id="autotoc_md15"></a>
12-13 Pyhelayers ext</h2>
<p>An overview of APIs. They repeat demos 02 and 03 using a different API.</p>
<h2><a class="anchor" id="autotoc_md16"></a>
14 COVID-19 Detection</h2>
<ul>
<li>Model type: Neural network</li>
<li>Network architecture:<ul>
<li>Conv2D, 16 filters, kernel 11x11, strides 4x4, valid padding.</li>
<li>Poly activation (degree 2).</li>
<li>Conv2D, 32 filters, kernel 11x11, strides 4x4, valid padding.</li>
<li>Poly activation (degree 2).</li>
<li>Conv2D, 64 filters, kernel 7x7, strides 1x1, valid padding.</li>
<li>Flatten.</li>
<li>Poly activation (degree 2).</li>
<li>FC of size 100.</li>
<li>Poly activation (degree 2).</li>
<li>FC of size 20.</li>
<li>Poly activation (degree 2).</li>
<li>FC of size 3.</li>
</ul>
</li>
<li>Input: an image of size 224x224x3.</li>
<li>Non-encrypted model weights.</li>
<li>Time &amp; memory performance (Machine 1):<ul>
<li>When optimized for latency: 19 seconds per sample, memory 24.4 GB.</li>
<li>Intermediate setting: 51 seconds per batch of 8 samples, memory 64.5 GB.</li>
</ul>
</li>
<li>FHE scheme: SEAL CKKS, security 128, depth 13, poly degree 2^15.<ul>
<li>Evaluation keys size: 2.9 GB</li>
</ul>
</li>
<li>Time performance in the clear: 2.339 seconds for 8 samples, 0.438 seconds for 1 sample.</li>
<li>FHE NeuralNet implementation inherits form HeModel.</li>
</ul>
<h2><a class="anchor" id="autotoc_md17"></a>
15 Logistic regression training over encrypted data</h2>
<ul>
<li>Model type: logistic regression.</li>
<li>Number of iterations: 3.</li>
<li>Input: a training set with 30 features and 984 samples.</li>
<li>Time &amp; memory performance (Machine 1): 20 seconds per a batch of 984 training samples, memory 6.5 GB.</li>
<li>FHE scheme: HEaaN CKKS, security 128, depth 13, poly degree 2^15.</li>
<li>Time performance in the clear: 0.1 seconds for 984 samples.</li>
<li>FHE LogisticRegression implementation inherits from HeModel.</li>
</ul>
<h2><a class="anchor" id="autotoc_md18"></a>
16 Completely random forest training over encrypted data</h2>
<ul>
<li>Model type: completely random forest.</li>
<li>Input: a vector of 149 elements.</li>
<li>Time &amp; memory performance (Machine 1):<ul>
<li>When fitting all the data once: 13.2 seconds for 32561 samples, memory 3.8 GB.</li>
<li>When fitting the data by batches of 4096: 18.7 seconds for 32561 samples, memory 1.7 GB.</li>
</ul>
</li>
<li>Time for plain AdaboostClassifier training (n_estimators=100): 3.5 seconds.</li>
<li>Time for plain RandomForestClassifier training (n_estimators=100, max_depth=3): 0.7 seconds.</li>
<li>FHE scheme: SEAL CKKS, security 128, depth 3, poly degree 2^14.<ul>
<li>Evaluation keys size: 66 MB.</li>
</ul>
</li>
<li>FHE implementation of Completely Random Forest does not inherit form HeModel</li>
</ul>
<h2><a class="anchor" id="autotoc_md19"></a>
17. Privacy Preserving Record Linkage (Entity Resolution)</h2>
<ul>
<li>Application: Find matching similar records in two databases while preserving privacy. The similarity metric is the Jaccard Index of the compared records, and the records are privately matched using Private-Set-Intersection.</li>
<li>Input: two relational databases given as files in csv format each with 0.5 million records, each record about 100 characters long.</li>
<li>Time &amp; memory performance (Machine 1):<ul>
<li>Test 1 - Compare 1000 records from each of the two Databases (default setup): Time: 2.780 secs Memory: 68 MB</li>
<li>Test 2 - Compare the entire two Databases, each with 0.5 million records: Time: ~14 min Memory: 25.15 GB</li>
</ul>
</li>
<li>Encryption details: uses Diffie-Hellman Key exchange protocol over Elliptic-Groups via OpenSSL 1.1.1f</li>
</ul>
<h2><a class="anchor" id="autotoc_md20"></a>
18. Arima training and prediction on encrypted data</h2>
<ul>
<li>Model type: ARIMA(1,1,1)</li>
<li>Input: A time series of 2^15 values</li>
<li>Time &amp; memory performance (Machine 1): 57 seconds for training and 42 seconds for prediction. Memory 13.7 GB</li>
<li>Evaluation key size: 227 MB.</li>
<li>FHE implementation of Arima does not inherit from HeModel.</li>
</ul>
<h2><a class="anchor" id="autotoc_md21"></a>
19. MLToolbox demonstration</h2>
<ul>
<li>Model type: Neural network</li>
<li>Network architecture: (0): Conv2d(3, 6, kernel_size=(5, 5), stride=(1, 1)) (1): TrainablePolyReLU(coefs=[0.13121649622917175, 0.053340282291173935]) (2): AvgPool2d(kernel_size=2, stride=2, padding=0) (3): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1)) (4): TrainablePolyReLU(coefs=[0.17864428460597992, 0.050597239285707474]) (5): AvgPool2d(kernel_size=2, stride=2, padding=0) (6): Flatten(start_dim=1, end_dim=-1) (7): Linear(in_features=400, out_features=120, bias=True) (8): TrainablePolyReLU(coefs=[0.1425626277923584, 0.0942169651389122]) (9): Linear(in_features=120, out_features=84, bias=True) (10): TrainablePolyReLU(coefs=[0.15955279767513275, 0.11093349754810333]) (11): Linear(in_features=84, out_features=10, bias=True)</li>
<li>Time &amp; memory performance (Machine 1):<ul>
<li>For whole notebook: 45 mins. Memory 14.5 GB.</li>
<li>For FHE prediction: 14.8 seconds for a batch of 20 samples.</li>
</ul>
</li>
<li>Evaluation key size: 1.6 GB.</li>
</ul>
<h2><a class="anchor" id="autotoc_md22"></a>
20. XGBoost prediction on encrypted data</h2>
<ul>
<li>Model type: XGBoost.</li>
<li>Architecture: 60 trees (20 for each of the three classes in the iris data) and maximum depth of 3 for each tree.</li>
<li>Input: A batch of up to 2^14 samples.</li>
<li>Evaluation keys size: 5 GB.</li>
<li>Time &amp; memory performance (Machine 1): Time: 1 minute and 15 seconds. Memory: 21GB.<ul>
<li>Run time and memory should scale linearly with number of trees and exponentially with the maximum depth of the trees.</li>
<li>Multiplication depth is 15 + log(max_depth) + 1, where max_depth is the maximum tree depth.</li>
</ul>
</li>
<li>FHE XGBoost implemenation does not inherit from HeModel.</li>
</ul>
<h2><a class="anchor" id="autotoc_md23"></a>
21. One-Hot encoding on encrypted data</h2>
<ul>
<li>Application: Calculate one-hot encoding under homomorphic encryption.</li>
<li>Input: A list of 16 numbers.</li>
<li>Time &amp; memory performance (Machine 1): Time: 0.378 seconds. Memory: 3 GB.</li>
<li>FHE scheme: SEAL CKKS, security 128, depth 10, poly degree 2^15.</li>
</ul>
<h2><a class="anchor" id="autotoc_md24"></a>
22. Private Set Intersection for Federated Learning using FHE</h2>
<ul>
<li>Application: calculate an encrypted dataset that contains only the samples that appear also in the datasets of the other parties, and do so without disclosing any information to each of the parties.</li>
<li>Input: A list 5 UIDs (each is unsigned integer) and a partial dataset to each of the 3 parties.</li>
<li>Time &amp; memory performance (Machine 1): Time: 20-30 minutes. Memory: 35 GB.</li>
<li>FHE scheme: HEaaN, security 128, depth 9, poly degree 2^16. </li>
</ul>
</div></div><!-- contents -->
</div><!-- PageDoc -->
<!-- HTML footer for doxygen 1.8.8-->
<!-- start footer part -->
</div>
</div>
</div>
</div>
</div>
<hr class="footer"/><address class="footer"><small>
Generated by &#160;<a href="http://www.doxygen.org/index.html">
<img class="footer" src="doxygen.png" alt="doxygen"/>
</a> 1.8.17
</small></address>
</body>
        <script type="text/javascript" src="doxy-boot.js"></script>
</html>
