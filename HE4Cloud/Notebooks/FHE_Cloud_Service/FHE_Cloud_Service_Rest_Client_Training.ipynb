{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FHE Cloud Service (HE4Cloud) Rest Client Training Demonstration\n",
    "Expected RAM usage: 3 GB.  \n",
    "Expected runtime: less than 3 minutes. \n",
    "   \n",
    "System Requirements  \n",
    "The IBM Fully Homomorphic Encryption(FHE) Service is a Cloud Services accessible via REST API, Requires an internet connection to issue HTTP request to service, such as via a browser. FHE Cloud Service Supports Chrome and Firefox browsers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Introduction\n",
    "The IBM Fully Homomorphic Encryption (FHE) Service is an early beta programme provided under the [Community Edition License](https://ibm.ent.box.com/s/zfl6rt2p09811nyy8yow8t3mpsmkmsw6) intended to help customers understand and develop use cases utilizing the power of FHE. This service enables data scientists and developers to deploy privacy preserving machine learning driven Software-as-a-Service (SaaS) applications in the Cloud.\n",
    "\n",
    "The IBM Fully Homomorphic Encryption (FHE) Service is powered by [HELayers](https://hub.docker.com/r/ibmcom/helayers-pylab) , IBM's FHE AI SDK.\n",
    "\n",
    "The underlying assumed Trust Model of the deployed application is such that the browser or the client initiating the requests to the deployed application is running in a trusted environment while the deployed application in the Cloud is running in an untrusted environment\n",
    "\n",
    "Since FHE allows for arbitrary computation over encrypted data, this Service enables clients to encrypt data in a trusted environment, send it for processing in an untrusted environment, receive the encrypted results of the processing and then decrypt in the trusted environment. This ensures that data, while not in the trusted environment is always encrypted, in transit, at rest and during compute.\n",
    "\n",
    "<img src=\"https://he4cloud.com/_nuxt/img/fhe-trust-env.341e66f.png\" style=\"background-color:white; width: 80%; height: 80%\" width=\"681\" height=\"303\"/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Flows\n",
    "### ML Model Owner Flow\n",
    "\n",
    "The ML Model owner must be a registered user of FHE Cloud Service. As an ML Model owner you can deploy a model, the deployment produces a \"ML Model base url\". This url endpoint exposes RESTful API that can be used to perform training and inference (prediction) on the ML Model, to manage the ML Model and manage its' FHE keys and retrieve usage information. The \"ML Model base url\" should be published to ML Model users so they can register to the ML Model and use it (see ML Model User Flow). You can also retrive the \"ML Model base url\" using a rest call to the FHE Cloud Service API based on ML Model details you specified on deployment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ML Model User Flow\n",
    "The user must be a registered user of the FHE Cloud Service. The user registers the ML model for training, creates public and secret context, uploads the public context, encrypts the ML model and the data using the secret context, uploads the encrypted data and encrypted ML model to the cloud, performs training on the encrypted ML model, receives back the encrypted trained ML model and decrypts the results. The user can save the secret context on his side or encrypt it and use the FHE Cloud Service API to upload and retrieve it. When the user unregisters from the ML model all the FHE Keys will be deleted."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Demo Use Case\n",
    "This example demonstrates how an encrypted logistic regression (LR) model can be trained in an untrusted public environment (i.e., cloud) with encrypted data, and how the predictions are carried out in the trusted environment (i.e., client) for validation of the trained model. \n",
    "\n",
    "The training is done over credit card fraud dataset  https://www.kaggle.com/mlg-ulb/creditcardfraud."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  1. Sign In/Sign Up\n",
    "Go to https://he4cloud.com/ click on to \"Sign In/Sign Up\" button.  \n",
    "- Sign Up: If you don't have a user yet select the Sign Up option and fill up your Username, Email and Password. you will receive a confirmation code to your email to confirm your account.\n",
    "- Sign In: If you already a user please use your Username and Password to Sign In."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Token And URL\n",
    "Go to https://he4cloud.com/ and select \"API\", you will see the \"API URL\" and your \"API TOKEN\", copy and paste them below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "API_URL     = \"http://172.17.0.1:5001/api/v0.1\"\n",
    "API_TOKEN   = \"eyJhbGciOiJSUzI1NiIsImtpZCI6IjI1MTM2MDE3ODQxMzI0MDMyNCJ9.eyJpc3MiOiJodHRwOi8vMTcyLjE3LjAuMTo4MDgwIiwic3ViIjoiMjUwODkwNjk4NjA4NDEwNjI4IiwiYXVkIjpbIjI1MDg5MDcwMzAzNzU5NTY1MkBoZTRjbG91ZC1wcm9qZWN0IiwiMjUwODkwNzAyNjAxMzIyNTAwIl0sImp0aSI6IjI1MTM2MDE3Nzk5MzgwOTkyNCIsImV4cCI6MTcwNjM2MTU0MSwiaWF0IjoxNzA2MzE4MzQxLCJuYmYiOjE3MDYzMTgzNDF9.f6o4g0pphS53nTdcsvW9EMABFsn5UoPacS3s97BqBGv02LgajGLYiI2V2-NC_E3Hfw9mAIXB4SDilgRi4RQ_-mRaxWidAMajEaTgHC3xxOjlIhM5LC75XXkInr_bgT5hDtqqG3hikHdHoLwXgQjatJZTPt6gqTo-_zRDV75srb1IFjORllmEPqc0bkmZL6ZPjRTXJrV7H83s7GeLQxBqFtmZmG7km-XD282xcz8epiREcT7xK0L61snifrFcVmUKPnEBf4vPhvVkOK_hVMhA6CPePoVVqSN2besg5vBpZl2oudD_Iz6MqnG2aSDnuljN1b911MvYmdvfq8WHNbnKqQ\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Start with some imports and installations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1. Requirements\n",
    "Make sure that you installed all the needed requiremnets (pip install requirements.txt). Also you need to install \"pyhelayers\". To get the needed \"phyelayers\" version go to https://he4cloud.com/ and select \"Help\". "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2. Import Packages "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**** GET http://172.17.0.1:5001/api/v0.1/info/version\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response code: 200 message: {\n",
      "  \"pyhelayers version\": \"1.5.4.0\",\n",
      "  \"server version\": \"v0.1\"\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from pathlib import Path\n",
    "from requests_toolbelt.multipart import encoder\n",
    "import json\n",
    "import os\n",
    "import h5py\n",
    "import time\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pyhelayers\n",
    "import matplotlib.patches as mpatches\n",
    "from importlib_metadata import version\n",
    "\n",
    "url = API_URL  + '/info/version'\n",
    "print(f'**** GET {url}')\n",
    "response = requests.get(headers={'Authorization' : 'Bearer ' + API_TOKEN}, url=url)\n",
    "response.raise_for_status()\n",
    "print(f'Response code: {response.status_code} message: {response.text}')\n",
    "server_pyhelayers_version = json.loads(response.text)[\"pyhelayers version\"]\n",
    "\n",
    "# Verify if \"pyhelayers\" is installed\n",
    "client_pyhelayers_version = version(\"pyhelayers\")\n",
    "if client_pyhelayers_version != server_pyhelayers_version:  \n",
    "    print(f'You are using pyhelayers {client_pyhelayers_version} and the server is using pyhelayers {server_pyhelayers_version}')\n",
    "    package = f'pyhelayers=={server_pyhelayers_version}'\n",
    "    raise Exception(f'The FHE Service requeries pyhelayers version {package}') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Load and prepare the dataset in the trusted environment\n",
    "\n",
    "Load and prepare the credit card fraud dataset for encryption in a trusted client environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 984 rows and 30 columns in our dataset.\n"
     ]
    }
   ],
   "source": [
    "INPUT_DIR = Path('lr_fraud_training/')\n",
    "file = INPUT_DIR / 'processed_creditcard_balanced_sample.csv'\n",
    "data = pd.read_csv(file, header=0)\n",
    "labels = (data.iloc[:, -1:]).to_numpy(dtype=np.float128)\n",
    "plain_samples = (data.iloc[:, :-1]).to_numpy(dtype=np.float128) \n",
    "batch_size = plain_samples.shape[0]\n",
    "number_of_features = plain_samples.shape[1]\n",
    "nRow, nCol = plain_samples.shape\n",
    "print(f'There are {nRow} rows and {nCol} columns in our dataset.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Initialize the encrypted LR model in the trusted envireonment and deply the LR model\n",
    "* A LogisticRegression object is initialized\n",
    "* A requirement configuration is supplied to internally determine the most suitable HE parameters\n",
    "* The encryption of the data is carried out"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.1. Initialize and encrypt the logistic regression model\n",
    "\n",
    "We can provide some additional `HyperParameters` and `HeRunRequirements` as inputs.\n",
    "\n",
    "The used hyper parameters are:\n",
    "* the number of iterations to be used in training, which is referred to by `hyper_params.number_of_iterations`\n",
    "* the learning rate for training, which is `hyper_params.learning_rate`\n",
    "* the activation used for training is a degree 3 polynomial approximation of the sigmoid function, and is referenced by `pyhelayers.LRActivation.SIGMOID_POLY_3`. \n",
    "\n",
    "In the HE run requirements, we set the batch size and rely on the default values for other parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyper_params = pyhelayers.PlainModelHyperParams()\n",
    "hyper_params.fit_hyper_params.number_of_epochs = 3\n",
    "hyper_params.fit_hyper_params.learning_rate = 0.1\n",
    "hyper_params.number_of_features = number_of_features\n",
    "hyper_params.trainable = True\n",
    "hyper_params.logistic_regression_activation = pyhelayers.LRActivation.SIGMOID_POLY_3\n",
    "\n",
    "he_run_req = pyhelayers.HeRunRequirements()\n",
    "# Request a HEaaN context if available, or a SEAL context otherwise\n",
    "he_run_req.set_he_context_options([pyhelayers.HeContext.create([\"HEaaN_CKKS\", \"SEAL_CKKS\"])])\n",
    "he_run_req.optimize_for_batch_size(batch_size)\n",
    "\n",
    "client_lr = pyhelayers.LogisticRegression()\n",
    "client_lr.encode_encrypt(files=[], he_run_req=he_run_req, hyper_params=hyper_params)\n",
    "client_context = client_lr.get_created_he_context()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.2. Deploy and initilize the LR model URL\n",
    "We deploy the LR model and create a URL. We will use this URL to execute operation on the LR model (e.g., register the user on that model, add profile, upload the ecnrypted model, upload the encrypted data, train the model, etc.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**** POST http://172.17.0.1:5001/api/v0.1/my_lr_fraud_model_train/v2/deploy_model\n",
      "Response code: 200 message: http://172.17.0.1:5001/api/v0.1/3868ea9d-89a5-4c16-9771-a1923d97d615/my_lr_fraud_model_train/v2/\n",
      "model url: http://172.17.0.1:5001/api/v0.1/3868ea9d-89a5-4c16-9771-a1923d97d615/my_lr_fraud_model_train/v2/\n"
     ]
    }
   ],
   "source": [
    "context_buffer = client_context.save_to_buffer()\n",
    "\n",
    "# deploy URL\n",
    "model_name = 'my_lr_fraud_model_train'\n",
    "model_version = 'v2'\n",
    "\n",
    "url = f'{API_URL}/{model_name}/{model_version}/deploy_model'\n",
    "print(f'**** POST {url}')\n",
    "response = requests.post(url=url, headers={'Authorization': 'Bearer ' + API_TOKEN}, data=\"\")\n",
    "response.raise_for_status()\n",
    "print(f'Response code: {response.status_code} message: {response.text}')\n",
    "model_url = response.text\n",
    "print(f'model url: {model_url}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. User Registration \n",
    "User registration requires two steps:\n",
    "- Register user for the ML Model (ML Model owner provides the \"ML Model base URL\")\n",
    "- Create a user profile based on user requirements. This is preparation to allow multiple profiles for a single user"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.1. Register User"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**** POST http://172.17.0.1:5001/api/v0.1/3868ea9d-89a5-4c16-9771-a1923d97d615/my_lr_fraud_model_train/v2/application/register_user\n",
      "Response code: 200 message: 250890698608410628 was registered as for service 3868ea9d-89a5-4c16-9771-a1923d97d615. \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# register user url\n",
    "url = model_url  + 'application/register_user'\n",
    "print(f'**** POST {url}')\n",
    "response = requests.post(headers={'Authorization' : 'Bearer ' + API_TOKEN}, url=url)\n",
    "response.raise_for_status()\n",
    "print(f'Response code: {response.status_code} message: {response.text}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.2. Add User Profile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**** POST http://172.17.0.1:5001/api/v0.1/3868ea9d-89a5-4c16-9771-a1923d97d615/my_lr_fraud_model_train/v2/add_profile\n",
      "Response code: 200 message: 9b0a9d08-ea06-48c1-82ca-90e109526380\n"
     ]
    }
   ],
   "source": [
    "# add User profile url\n",
    "url = model_url  + 'add_profile'\n",
    "print(f'**** POST {url}')\n",
    "# optimizer_requirements = json.dumps({\"batchSize\": 16})\n",
    "response = requests.post(headers={'Authorization' : 'Bearer ' + API_TOKEN}, url=url) #data=optimizer_requirements)\n",
    "response.raise_for_status()\n",
    "print(f'Response code: {response.status_code} message: {response.text}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Create FHE Keys From FHE Context\n",
    "FHE context is a FHE object that can generate the set of public and private FHE keys."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> encryption key Saved\n",
      ">> evaluation keys Saved\n",
      ">> secret key Saved\n"
     ]
    }
   ],
   "source": [
    "# Save the encryption key\n",
    "pf=pyhelayers.PublicFunctions()\n",
    "pf.clear()\n",
    "pf.encrypt=True\n",
    "public_context_buffer_enc=client_context.save_to_buffer(pf) \n",
    "print('>> encryption key Saved')\n",
    "\n",
    "    \n",
    "# Save all but the encryption key (evaluation keys)\n",
    "pf=pyhelayers.PublicFunctions()\n",
    "pf.encrypt=False\n",
    "public_context_buffer_eva=client_context.save_to_buffer()\n",
    "print('>> evaluation keys Saved')\n",
    "\n",
    "# LOCAL: save to buffer (secret_key)\n",
    "secret_key = client_context.save_secret_key(True)\n",
    "print('>> secret key Saved')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. Upload Keys\n",
    "Uploading the key is a two step procedure. First we generate presigned upload URL and use the presigned URL to upload the key.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 8.1. Upload Evaluation Key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**** POST http://172.17.0.1:5001/api/v0.1/3868ea9d-89a5-4c16-9771-a1923d97d615/my_lr_fraud_model_train/v2/upload/evaluation_key_url\n",
      "Response code: 200 message: http://172.17.0.1:9000/3868ea9d-89a5-4c16-9771-a1923d97d615/UF_3868ea9d-89a5-4c16-9771-a1923d97d615_my_lr_fraud_model_train_v2_9b0a9d08-ea06-48c1-82ca-90e109526380_eva.key?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=minioadmin%2F20240127%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20240127T012023Z&X-Amz-Expires=60&X-Amz-SignedHeaders=content-type%3Bhost&X-Amz-Signature=91702f4b9d74b93eef0db177b89602cf9a99b56b717b4da4ea0a1bddd0c825f2\n",
      "**** PUT b'http://172.17.0.1:9000/3868ea9d-89a5-4c16-9771-a1923d97d615/UF_3868ea9d-89a5-4c16-9771-a1923d97d615_my_lr_fraud_model_train_v2_9b0a9d08-ea06-48c1-82ca-90e109526380_eva.key?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=minioadmin%2F20240127%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20240127T012023Z&X-Amz-Expires=60&X-Amz-SignedHeaders=content-type%3Bhost&X-Amz-Signature=91702f4b9d74b93eef0db177b89602cf9a99b56b717b4da4ea0a1bddd0c825f2'\n",
      "Response code: 200 message: \n",
      "<< Evaluation Key Uploaded Successfully\n"
     ]
    }
   ],
   "source": [
    "iop_buffer = None\n",
    "# Evaluation Key upload url\n",
    "url = model_url  + 'upload/evaluation_key_url'\n",
    "print(f'**** POST {url}')\n",
    "headers = { \n",
    "    'Content-Type': 'application/octet-stream' \n",
    "}\n",
    "response = requests.post(url=url, headers={'Authorization' : 'Bearer ' + API_TOKEN})\n",
    "response.raise_for_status()\n",
    "print(f'Response code: {response.status_code} message: {response.text}')\n",
    "\n",
    "# Evaluation Key presigned upload url\n",
    "presigned_upload_ulr = response.content\n",
    "print(f'**** PUT {presigned_upload_ulr}')\n",
    "response = requests.put(presigned_upload_ulr, data=public_context_buffer_eva, headers=headers)\n",
    "response.raise_for_status()\n",
    "print(f'Response code: {response.status_code} message: {response.text}')\n",
    "\n",
    "print(f'<< Evaluation Key Uploaded Successfully')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 8.2. Upload Public Key (Encryption Key)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**** POST http://172.17.0.1:5001/api/v0.1/3868ea9d-89a5-4c16-9771-a1923d97d615/my_lr_fraud_model_train/v2/upload/public_key_url\n",
      "Response code: 200 message: http://172.17.0.1:9000/3868ea9d-89a5-4c16-9771-a1923d97d615/UF_3868ea9d-89a5-4c16-9771-a1923d97d615_my_lr_fraud_model_train_v2_9b0a9d08-ea06-48c1-82ca-90e109526380_enc.key?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=minioadmin%2F20240127%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20240127T012034Z&X-Amz-Expires=60&X-Amz-SignedHeaders=content-type%3Bhost&X-Amz-Signature=594b7a8c1897c833a01aa34e6d8e4daa865250c0033320ee20abc60c4a17fa49\n",
      "**** PUT b'http://172.17.0.1:9000/3868ea9d-89a5-4c16-9771-a1923d97d615/UF_3868ea9d-89a5-4c16-9771-a1923d97d615_my_lr_fraud_model_train_v2_9b0a9d08-ea06-48c1-82ca-90e109526380_enc.key?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=minioadmin%2F20240127%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20240127T012034Z&X-Amz-Expires=60&X-Amz-SignedHeaders=content-type%3Bhost&X-Amz-Signature=594b7a8c1897c833a01aa34e6d8e4daa865250c0033320ee20abc60c4a17fa49'\n",
      "Response code: 200 message: \n",
      "<< Public Key Uploaded Successfully\n"
     ]
    }
   ],
   "source": [
    "# public key upload url\n",
    "url = model_url  + 'upload/public_key_url'\n",
    "print(f'**** POST {url}')\n",
    "response = requests.post(url=url, headers={'Authorization' : 'Bearer ' + API_TOKEN})\n",
    "response.raise_for_status()\n",
    "print(f'Response code: {response.status_code} message: {response.text}')\n",
    "\n",
    "# Public Key presigned upload url\n",
    "upload_ulr = response.content\n",
    "print(f'**** PUT {upload_ulr}')\n",
    "response = requests.put(upload_ulr, data=public_context_buffer_enc, headers=headers)\n",
    "response.raise_for_status()\n",
    "print(f'Response code: {response.status_code} message: {response.text}')\n",
    "print(f'<< Public Key Uploaded Successfully')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 8.3. Upload Secret Key\n",
    "FHE Cloud Service allows the user to upload/download secret key, it's recommended to encrypt the secret key before uploading it. There are usecases (like a browser application) when there is no secure storage on client side. The solution â€“ encrypt secret key with an external facility (KMS of a kind), and store the encrypted key in cloud. Here we simulate it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**** POST http://172.17.0.1:5001/api/v0.1/3868ea9d-89a5-4c16-9771-a1923d97d615/my_lr_fraud_model_train/v2/upload/encryption_seed_url\n",
      "Response code: 200\n",
      "**** PUT b'http://172.17.0.1:9000/3868ea9d-89a5-4c16-9771-a1923d97d615/UF_3868ea9d-89a5-4c16-9771-a1923d97d615_my_lr_fraud_model_train_v2_9b0a9d08-ea06-48c1-82ca-90e109526380_enc.seed?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=minioadmin%2F20240127%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20240127T012049Z&X-Amz-Expires=60&X-Amz-SignedHeaders=content-type%3Bhost&X-Amz-Signature=0921b28e91e525820a38fb8cd34afd0e008bbf41ca7586899bbbd2e3f4c70e05'\n",
      "Response code: 200\n",
      "<< Encrypted Secret Key Uploaded Successfully\n"
     ]
    }
   ],
   "source": [
    "url = model_url  + 'upload/encryption_seed_url'\n",
    "print(f'**** POST {url}')\n",
    "response = requests.post(url=url, headers={'Authorization' : 'Bearer ' + API_TOKEN})\n",
    "response.raise_for_status()\n",
    "print(f'Response code: {response.status_code}')\n",
    "\n",
    "# Secret Key presigned upload url\n",
    "upload_ulr = response.content\n",
    "print(f'**** PUT {upload_ulr}')\n",
    "# it's recommended to encrypt the secret key before uploading it\n",
    "response = requests.put(upload_ulr, data=secret_key, headers=headers)\n",
    "response.raise_for_status()\n",
    "print(f'Response code: {response.status_code}')\n",
    "print(f'<< Encrypted Secret Key Uploaded Successfully')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9. Encrypts the LR model and the data in the trusted environment "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training data has been encrypted.\n"
     ]
    }
   ],
   "source": [
    "model_io_encoder = pyhelayers.ModelIoEncoder(client_lr)\n",
    "encrypted_inputs = pyhelayers.EncryptedData(client_context)\n",
    "model_io_encoder.encode_encrypt(encrypted_inputs, [plain_samples, labels])\n",
    "lr_buffer = client_lr.save_to_buffer()\n",
    "inputs_buffer = encrypted_inputs.save_to_buffer()\n",
    "print('training data has been encrypted.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10. Upload the LR encrypted model and the encrypted data to the untrusted environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**** POST http://172.17.0.1:5001/api/v0.1/3868ea9d-89a5-4c16-9771-a1923d97d615/my_lr_fraud_model_train/v2/upload/upload_encrypted_model_url\n",
      "**** POST http://172.17.0.1:5001/api/v0.1/3868ea9d-89a5-4c16-9771-a1923d97d615/my_lr_fraud_model_train/v2/data/upload/data_url\n",
      "Context, model, and samples saved\n"
     ]
    }
   ],
   "source": [
    "url = model_url  + 'upload/upload_encrypted_model_url'\n",
    "response = requests.post(url=url, headers={'Authorization': 'Bearer ' + API_TOKEN})\n",
    "print(f'**** POST {url}')\n",
    "if response.status_code != 200:\n",
    "    print(f'<< response_code7 {response.status_code}')\n",
    "    print(f'<< message {response.text}')\n",
    "    raise Exception('<< server_upload_enc_model failed; response_code {response.status_code}')\n",
    "upload_ulr = response.content\n",
    "response = requests.put(upload_ulr, data=lr_buffer, headers = {'Content-Type': 'application/octet-stream'})\n",
    "if response.status_code != 200:\n",
    "    raise Exception('<< server_upload_enc_model failed; response_code {response.status_code}')\n",
    "\n",
    "url = model_url  + 'data' + '/upload/data_url'\n",
    "print(f'**** POST {url}')\n",
    "response = requests.post(url=url, headers={'Authorization': 'Bearer ' + API_TOKEN})\n",
    "if response.status_code != 200:\n",
    "    print(f'<< message {response.text}')\n",
    "    raise Exception(f'<< upload_data failed; response_code {response.status_code}')\n",
    "upload_ulr_set = json.loads(response.content)\n",
    "response = requests.put(upload_ulr_set[\"trainDataUrl\"][0], data=inputs_buffer, headers = {'Content-Type': 'application/octet-stream' })\n",
    "if response.status_code != 200:\n",
    "    raise Exception(f'<< upload_data failed; response_code {response.status_code}')\n",
    "\n",
    "print('Context, model, and samples saved')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 11. Perform training of the LR model in the untrusted environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<< Status: Running\n",
      "<< Status: Running\n",
      "<< Status: Running\n",
      "<< Status: Running\n",
      "<< Status: Running\n",
      "<< Status: Running\n",
      "<< Status: Running\n",
      "<< Status: Running\n",
      "<< Status: Running\n",
      "<< Status: Running\n",
      "<< Status: Running\n",
      "<< Status: Running\n",
      "<< Status: Running\n",
      "<< Status: Running\n",
      "<< Status: Running\n",
      "<< Status: Running\n",
      "<< Status: Running\n",
      "<< Status: Running\n",
      "<< Status: Running\n",
      "<< Status: Running\n",
      "<< Status: Running\n",
      "<< Status: Running\n",
      "<< Status: Running\n",
      "<< Status: Running\n",
      "<< Status: Running\n",
      "<< Status: Running\n",
      "<< Status: Running\n",
      "<< Status: Running\n",
      "<< Status: Running\n",
      "<< Status: Running\n",
      "<< Status: Running\n",
      "<< Status: Running\n",
      "<< Status: Running\n",
      "<< Status: Running\n",
      "<< Status: Running\n",
      "<< Status: Running\n",
      "<< Status: Running\n",
      "<< Status: Running\n",
      "<< Status: Running\n",
      "<< Status: Running\n",
      "<< Status: Running\n",
      "<< Status: Running\n",
      "<< Status: Running\n",
      "<< Status: Running\n",
      "<< Status: Running\n",
      "<< Status: Running\n"
     ]
    }
   ],
   "source": [
    "url = model_url + 'train/data?sync=False' \n",
    "#print(f'**** POST {url}')\n",
    "response = requests.post(headers={'Authorization' : 'Bearer ' + API_TOKEN} , url=url)\n",
    "if response.status_code == 200:\n",
    "    train_url = response.text\n",
    "    url = train_url  + \"check_status\"\n",
    "    status = 'Running'\n",
    "    while (status == 'Running'):\n",
    "        #print(f'**** GET {url} ')\n",
    "        response = requests.get(headers={'Authorization' : 'Bearer ' + API_TOKEN} , url=url)\n",
    "        if response.status_code == 200:\n",
    "            status = response.text\n",
    "            print(f'<< Status: {status}')\n",
    "        else:\n",
    "            #print(f'<< response_code_cs {response.status_code}')\n",
    "            #print(f'<< response_text_cs {response.text}')\n",
    "            raise Exception(f'<< train failed; response_code {response.status_code}')\n",
    "        time.sleep(5)\n",
    "    url = train_url  + \"get_results\"\n",
    "    #print(f'**** GET {url}')\n",
    "    response = requests.get(headers={'Authorization' : 'Bearer ' + API_TOKEN}, url=url)\n",
    "    if response.status_code == 200:\n",
    "        trained_model_buffer = response.content\n",
    "        #print('<<<< Leaving server_predict()')\n",
    "        if (status != 'Completed'):\n",
    "            #print(f'<< response_code {response.status_code}')\n",
    "            #print(f'<< message {response.text}')\n",
    "            raise Exception(f'<< train failed; response_code {response.status_code}')\n",
    "    else:\n",
    "        #print(f'<< response_code {response.status_code}')\n",
    "        #print(f'<< message {response.text}')\n",
    "        raise Exception(f'<< train failed; response_code {response.status_code}')\n",
    "else:\n",
    "    #print(f'<< response_code {response.status_code}')\n",
    "    #print(f'<< message {response.text}')\n",
    "    raise Exception(f'<< train failed; response_code {response.status_code}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 12. Get the trained model from the untrusted environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "url = model_url  + 'get_encrypted_model'\n",
    "print(f'**** GET {url}')\n",
    "response = requests.get(headers={'Authorization' : 'Bearer ' + API_TOKEN}, url=url)\n",
    "status_code = response.status_code\n",
    "print(f'>> response: {status_code}')\n",
    "if status_code == 200 and response.content:\n",
    "    model_buffer = response.content\n",
    "else:\n",
    "    print(f'<<<< response_code {response.status_code}')\n",
    "    print(f'<< message {response.text}')\n",
    "    raise Exception(f'<< client_decrypt_model failed; response_code {response.status_code}')\n",
    "\n",
    "enc_model = pyhelayers.load_he_model(client_context, model_buffer)     \n",
    "trained_plain = enc_model.decrypt_decode()\n",
    "print(f'<<<< encrypted model loaded')\n",
    "\n",
    "print('Predictions loaded and decrypted.')\n",
    "print(trained_plain)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 13. Perform predictions on the trained model in the trusted environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plain_predictions = trained_plain.predict([plain_samples])[0]\n",
    "plain_predictions = plain_predictions.reshape(plain_predictions.shape[0], 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 14. Unregister User\n",
    "User can unregister from the ML Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = model_url  + 'application/unregister_user'\n",
    "print(f'**** DELETE {url}')\n",
    "response = requests.delete(headers={'Authorization' : 'Bearer ' + API_TOKEN}, url=url)\n",
    "response.raise_for_status()\n",
    "print(f'Response code: {response.status_code} message: {response.text}')\n",
    "print('<< successfully unregistered user.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 15. Undeploy Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# undeploy medel url\n",
    "url = f'{API_URL}/{model_name}/{model_version}/undeploy_model'\n",
    "print(f'**** DELETE {url}')\n",
    "response = requests.delete(headers={'Authorization' : 'Bearer ' + API_TOKEN}, url=url)\n",
    "response.raise_for_status()\n",
    "print(f'Response code: {response.status_code} message: {response.text}')\n",
    "print('<< successfully undeployed model.')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
