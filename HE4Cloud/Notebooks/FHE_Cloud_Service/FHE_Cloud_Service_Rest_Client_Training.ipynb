{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FHE Cloud Service (HE4Cloud) Rest Client Training Demonstration\n",
    "Expected RAM usage: 3 GB.  \n",
    "Expected runtime: less than 3 minutes. \n",
    "   \n",
    "System Requirements  \n",
    "The IBM Fully Homomorphic Encryption(FHE) Service is a Cloud Services accessible via REST API, Requires an internet connection to issue HTTP request to service, such as via a browser. FHE Cloud Service Supports Chrome and Firefox browsers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Introduction\n",
    "The IBM Fully Homomorphic Encryption (FHE) Service is an early beta programme provided under the [Community Edition License](https://ibm.ent.box.com/s/zfl6rt2p09811nyy8yow8t3mpsmkmsw6) intended to help customers understand and develop use cases utilizing the power of FHE. This service enables data scientists and developers to deploy privacy preserving machine learning driven Software-as-a-Service (SaaS) applications in the Cloud.\n",
    "\n",
    "The IBM Fully Homomorphic Encryption (FHE) Service is powered by [HELayers](https://hub.docker.com/r/ibmcom/helayers-pylab) , IBM's FHE AI SDK.\n",
    "\n",
    "The underlying assumed Trust Model of the deployed application is such that the browser or the client initiating the requests to the deployed application is running in a trusted environment while the deployed application in the Cloud is running in an untrusted environment\n",
    "\n",
    "Since FHE allows for arbitrary computation over encrypted data, this Service enables clients to encrypt data in a trusted environment, send it for processing in an untrusted environment, receive the encrypted results of the processing and then decrypt in the trusted environment. This ensures that data, while not in the trusted environment is always encrypted, in transit, at rest and during compute.\n",
    "\n",
    "<img src=\"https://he4cloud.com/_nuxt/img/fhe-trust-env.341e66f.png\" style=\"background-color:white; width: 80%; height: 80%\" width=\"681\" height=\"303\"/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Flows\n",
    "### ML Model Owner Flow\n",
    "\n",
    "The ML Model owner must be a registered user of FHE Cloud Service. As an ML Model owner you can deploy a model, the deployment produces a \"ML Model base url\". This url endpoint exposes RESTful API that can be used to perform training and inference (prediction) on the ML Model, to manage the ML Model and manage its' FHE keys and retrieve usage information. The \"ML Model base url\" should be published to ML Model users so they can register to the ML Model and use it (see ML Model User Flow). You can also retrive the \"ML Model base url\" using a rest call to the FHE Cloud Service API based on ML Model details you specified on deployment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ML Model User Flow\n",
    "The user must be a registered user of the FHE Cloud Service. To be able to perform operations (e.g. training) on the ML Model, the user requests the \"ML Model base url\" from the owner, registers to the ML Model, creates public and secret context, uploads the public context, encrypts the data using the secret context, performs training on the ML Model and decrypts the results. The user can save the secret context on his side or encrypt it and use the FHE Cloud Service API to upload and retrive it. When the user unregisters from the ML Model all the FHE Keys will be deleted.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Demo Use Case\n",
    "This example demonstrates how an encrypted logistic regression (LR) model can be trained in an untrusted environment with encrypted data. Predictions are also carried out in the untrusted public environment for validation of the trained model. Prediction results are encrypted and sent back to the data owner to be decrypted in a trusted environment.\n",
    "\n",
    "The training is done over creditcardfraud dataset https://www.kaggle.com/mlg-ulb/creditcardfraud [1]-[9]."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  1. Sign In/Sign Up\n",
    "Go to https://he4cloud.com/ click on to \"Sign In/Sign Up\" button.  \n",
    "- Sign Up: If you don't have a user yet select the Sign Up option and fill up your Username, Email and Password. you will receive a confirmation code to your email to confirm your account.\n",
    "- Sign In: If you already a user please use your Username and Password to Sign In."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Token And URL\n",
    "Go to https://he4cloud.com/ and select \"API\", you will see the \"API URL\" and your \"API TOKEN\", copy and paste them below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "API_URL     = \"http://172.17.0.1:5001/api/v0.1\"\n",
    "API_TOKEN   = \"eyJhbGciOiJSUzI1NiIsImtpZCI6IjI1MTI3NjQwMDI3Nzg0ODA2OCJ9.eyJpc3MiOiJodHRwOi8vMTcyLjE3LjAuMTo4MDgwIiwic3ViIjoiMjUwODkwNjk4NjA4NDEwNjI4IiwiYXVkIjpbIjI1MDg5MDcwMzAzNzU5NTY1MkBoZTRjbG91ZC1wcm9qZWN0IiwiMjUwODkwNzAyNjAxMzIyNTAwIl0sImp0aSI6IjI1MTI3NjM5OTg0MTY0MDQ1MiIsImV4cCI6MTcwNjMxMTYwNSwiaWF0IjoxNzA2MjY4NDA1LCJuYmYiOjE3MDYyNjg0MDV9.l_mVw1QGztFQmJTeU59EJA8pTrggGhx_Oa-WviZb5sCIgQ1Y7pF8rgSp4kRfqisKTnaKLiRoQrouiUCWdcdhTP6l2V3sahbUccLpwY24pR8sxRmRIP5XjCSftoMlVk8kmC7aB3h0pdy_QNih15UGPOg_SSwaW1R3pf88vm2xM6O80ejBY5xEmVHPy3iU_u-gDV2Blg9Cjt9H9GJP8t2yCSN1y1-xGzFtE7k81PWKmCP-3IlA9llqTrBSyQfF8_Wijj5lHZd9NC-hruyUhJaNEi8ZbBPKT8y_b-IgwdomfWPLCV8u4lbRPKkyWdMtUJhN1YO6n8W8J6HOuGKiZv8XBQ\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Start with some imports and installations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1. Requirements\n",
    "Make sure that you installed all the needed requiremnets (pip install requirements.txt). Also you need to install \"pyhelayers\". To get the needed \"phyelayers\" version go to https://he4cloud.com/ and select \"Help\". "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2. Import Packages "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from pathlib import Path\n",
    "from requests_toolbelt.multipart import encoder\n",
    "import json\n",
    "import os\n",
    "import h5py\n",
    "import time\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pyhelayers\n",
    "import matplotlib.patches as mpatches\n",
    "from importlib_metadata import version\n",
    "\n",
    "url = API_URL  + '/info/version'\n",
    "print(f'**** GET {url}')\n",
    "response = requests.get(headers={'Authorization' : 'Bearer ' + API_TOKEN}, url=url)\n",
    "response.raise_for_status()\n",
    "print(f'Response code: {response.status_code} message: {response.text}')\n",
    "server_pyhelayers_version = json.loads(response.text)[\"pyhelayers version\"]\n",
    "\n",
    "# Verify if \"pyhelayers\" is installed\n",
    "client_pyhelayers_version = version(\"pyhelayers\")\n",
    "if client_pyhelayers_version != server_pyhelayers_version:  \n",
    "    print(f'You are using pyhelayers {client_pyhelayers_version} and the server is using pyhelayers {server_pyhelayers_version}')\n",
    "    package = f'pyhelayers=={server_pyhelayers_version}'\n",
    "    raise Exception(f'The FHE Service requeries pyhelayers version {package}') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4. Load and prepare the dataset in the trusted environment\n",
    "\n",
    "Load and prepare the credit card fraud dataset for encryption in a trusted client environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_DIR = Path('lr_fraud_training/')\n",
    "file = INPUT_DIR / 'processed_creditcard_balanced_sample.csv'\n",
    "data = pd.read_csv(file, header=0)\n",
    "labels = (data.iloc[:, -1:]).to_numpy(dtype=np.float128)\n",
    "\n",
    "plain_samples = (data.iloc[:, :-1]).to_numpy(dtype=np.float128) \n",
    "batch_size = plain_samples.shape[0]\n",
    "number_of_features = plain_samples.shape[1]\n",
    "\n",
    "nRow, nCol = plain_samples.shape\n",
    "print(f'There are {nRow} rows and {nCol} columns in our dataset.')\n",
    "# data.info(verbose=True, memory_usage='deep')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5. Initialize model and encrypt data in a trusted envireonment\n",
    "* A LogisticRegression object is initialized\n",
    "* A requirement configuration is supplied to internally determine the most suitable HE parameters\n",
    "* The encryption of the data is carried out"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.1. Initialize and encrypt the logistic regression model\n",
    "\n",
    "We can provide some additional `HyperParameters` and `HeRunRequirements` as inputs.\n",
    "\n",
    "The used hyper parameters are:\n",
    "* the number of iterations to be used in training, which is referred to by `hyper_params.number_of_iterations`\n",
    "* the learning rate for training, which is `hyper_params.learning_rate`\n",
    "* the activation used for training is a degree 3 polynomial approximation of the sigmoid function, and is referenced by `pyhelayers.LRActivation.SIGMOID_POLY_3`. \n",
    "\n",
    "In the HE run requirements, we set the batch size and rely on the default values for other parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyper_params = pyhelayers.PlainModelHyperParams()\n",
    "hyper_params.fit_hyper_params.number_of_epochs = 3\n",
    "hyper_params.fit_hyper_params.learning_rate = 0.1\n",
    "hyper_params.number_of_features = number_of_features\n",
    "hyper_params.trainable = True\n",
    "hyper_params.logistic_regression_activation = pyhelayers.LRActivation.SIGMOID_POLY_3\n",
    "\n",
    "he_run_req = pyhelayers.HeRunRequirements()\n",
    "# Request a HEaaN context if available, or a SEAL context otherwise\n",
    "he_run_req.set_he_context_options([pyhelayers.HeContext.create([\"HEaaN_CKKS\", \"SEAL_CKKS\"])])\n",
    "he_run_req.optimize_for_batch_size(batch_size)\n",
    "\n",
    "client_lr = pyhelayers.LogisticRegression()\n",
    "client_lr.encode_encrypt(files=[], he_run_req=he_run_req, hyper_params=hyper_params)\n",
    "client_context = client_lr.get_created_he_context()\n",
    "\n",
    "# LOCAL: save to buffer (secret_key)\n",
    "secret_key = client_context.save_secret_key(True)\n",
    "print('>> secret key Saved')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.2. Encrypt the data in a trusted environment\n",
    "\n",
    "The plaintext samples and labels are encrypted:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_io_encoder = pyhelayers.ModelIoEncoder(client_lr)\n",
    "\n",
    "encrypted_inputs = pyhelayers.EncryptedData(client_context)\n",
    "model_io_encoder.encode_encrypt(encrypted_inputs, [plain_samples, labels])\n",
    "print('training data has been encrypted.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.3. Save and send\n",
    "We save the encrypted model, the context, and the samples in preparation for sending them to the server."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_buffer = client_lr.save_to_buffer()\n",
    "inputs_buffer = encrypted_inputs.save_to_buffer()\n",
    "context_buffer = client_context.save_to_buffer()\n",
    "\n",
    "# deploy URL\n",
    "model_name = 'my_lr_fraud_model_train'\n",
    "model_version = 'v2'\n",
    "\n",
    "url = f'{API_URL}/{model_name}/{model_version}/deploy_model'\n",
    "print(f'**** POST {url}')\n",
    "response = requests.post(url=url, headers={'Authorization': 'Bearer ' + API_TOKEN}, data=\"\")\n",
    "response.raise_for_status()\n",
    "print(f'Response code: {response.status_code} message: {response.text}')\n",
    "model_url = response.text\n",
    "print(f'model url: {model_url}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. User Registration \n",
    "User registration requires two steps:\n",
    "- Register user for the ML Model (ML Model owner provides the \"ML Model base URL\")\n",
    "- Create a user profile based on user requirements. This is preparation to allow multiple profiles for a single user"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.1. Register User"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# register user url\n",
    "url = model_url  + 'application/register_user'\n",
    "print(f'**** POST {url}')\n",
    "response = requests.post(headers={'Authorization' : 'Bearer ' + API_TOKEN}, url=url)\n",
    "response.raise_for_status()\n",
    "print(f'Response code: {response.status_code} message: {response.text}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.2. Add User Profile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add User profile url\n",
    "url = model_url  + 'add_profile'\n",
    "print(f'**** POST {url}')\n",
    "# optimizer_requirements = json.dumps({\"batchSize\": 16})\n",
    "response = requests.post(headers={'Authorization' : 'Bearer ' + API_TOKEN}, url=url) #data=optimizer_requirements)\n",
    "response.raise_for_status()\n",
    "print(f'Response code: {response.status_code} message: {response.text}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Create FHE Keys From FHE Context\n",
    "FHE context is a FHE object that can generate the set of public and private FHE keys."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the encryption key\n",
    "pf=pyhelayers.PublicFunctions()\n",
    "pf.clear()\n",
    "pf.encrypt=True\n",
    "public_context_buffer_enc=client_context.save_to_buffer(pf) \n",
    "print('>> encryption key Saved')\n",
    "\n",
    "    \n",
    "# Save all but the encryption key (evaluation keys)\n",
    "pf=pyhelayers.PublicFunctions()\n",
    "pf.encrypt=False\n",
    "public_context_buffer_eva=client_context.save_to_buffer()\n",
    "print('>> evaluation keys Saved')\n",
    "\n",
    "# LOCAL: save to buffer (secret_key)\n",
    "secret_key = client_context.save_secret_key(True)\n",
    "print('>> secret key Saved')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Upload Keys\n",
    "Uploading the key is a two step procedure. First we generate presigned upload URL and use the presigned URL to upload the key.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7.1. Upload Evaluation Key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iop_buffer = None\n",
    "# Evaluation Key upload url\n",
    "url = model_url  + 'upload/evaluation_key_url'\n",
    "print(f'**** POST {url}')\n",
    "headers = { \n",
    "    'Content-Type': 'application/octet-stream' \n",
    "}\n",
    "response = requests.post(url=url, headers={'Authorization' : 'Bearer ' + API_TOKEN})\n",
    "response.raise_for_status()\n",
    "print(f'Response code: {response.status_code} message: {response.text}')\n",
    "\n",
    "# Evaluation Key presigned upload url\n",
    "presigned_upload_ulr = response.content\n",
    "print(f'**** PUT {presigned_upload_ulr}')\n",
    "response = requests.put(presigned_upload_ulr, data=public_context_buffer_eva, headers=headers)\n",
    "response.raise_for_status()\n",
    "print(f'Response code: {response.status_code} message: {response.text}')\n",
    "\n",
    "print(f'<< Evaluation Key Uploaded Successfully')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7.2. Upload Public Key (Encryption Key)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# public key upload url\n",
    "url = model_url  + 'upload/public_key_url'\n",
    "print(f'**** POST {url}')\n",
    "response = requests.post(url=url, headers={'Authorization' : 'Bearer ' + API_TOKEN})\n",
    "response.raise_for_status()\n",
    "print(f'Response code: {response.status_code} message: {response.text}')\n",
    "\n",
    "# Public Key presigned upload url\n",
    "upload_ulr = response.content\n",
    "print(f'**** PUT {upload_ulr}')\n",
    "response = requests.put(upload_ulr, data=public_context_buffer_enc, headers=headers)\n",
    "response.raise_for_status()\n",
    "print(f'Response code: {response.status_code} message: {response.text}')\n",
    "print(f'<< Public Key Uploaded Successfully')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7.3. Upload Secret Key\n",
    "FHE Cloud Service allows the user to upload/download secret key, it's recommended to encrypt the secret key before uploading it. There are usecases (like a browser application) when there is no secure storage on client side. The solution â€“ encrypt secret key with an external facility (KMS of a kind), and store the encrypted key in cloud. Here we simulate it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "url = model_url  + 'upload/encryption_seed_url'\n",
    "print(f'**** POST {url}')\n",
    "response = requests.post(url=url, headers={'Authorization' : 'Bearer ' + API_TOKEN})\n",
    "response.raise_for_status()\n",
    "print(f'Response code: {response.status_code}')\n",
    "\n",
    "# Secret Key presigned upload url\n",
    "upload_ulr = response.content\n",
    "print(f'**** PUT {upload_ulr}')\n",
    "# it's recommended to encrypt the secret key before uploading it\n",
    "response = requests.put(upload_ulr, data=secret_key, headers=headers)\n",
    "response.raise_for_status()\n",
    "print(f'Response code: {response.status_code}')\n",
    "print(f'<< Encrypted Secret Key Uploaded Successfully')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = model_url  + 'upload/upload_encrypted_model_url'\n",
    "response = requests.post(url=url, headers={'Authorization': 'Bearer ' + API_TOKEN})\n",
    "print(f'**** POST {url}')\n",
    "if response.status_code != 200:\n",
    "    print(f'<< response_code7 {response.status_code}')\n",
    "    print(f'<< message {response.text}')\n",
    "    raise Exception('<< server_upload_enc_model failed; response_code {response.status_code}')\n",
    "upload_ulr = response.content\n",
    "response = requests.put(upload_ulr, data=lr_buffer, headers = {'Content-Type': 'application/octet-stream'})\n",
    "if response.status_code != 200:\n",
    "    raise Exception('<< server_upload_enc_model failed; response_code {response.status_code}')\n",
    "\n",
    "url = model_url  + 'data' + '/upload/data_url'\n",
    "print(f'**** POST {url}')\n",
    "response = requests.post(url=url, headers={'Authorization': 'Bearer ' + API_TOKEN})\n",
    "if response.status_code != 200:\n",
    "    print(f'<< message {response.text}')\n",
    "    raise Exception(f'<< upload_data failed; response_code {response.status_code}')\n",
    "upload_ulr_set = json.loads(response.content)\n",
    "response = requests.put(upload_ulr_set[\"trainDataUrl\"][0], data=inputs_buffer, headers = {'Content-Type': 'application/octet-stream' })\n",
    "if response.status_code != 200:\n",
    "    raise Exception(f'<< upload_data failed; response_code {response.status_code}')\n",
    "\n",
    "print('Context, model, and samples saved')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = model_url + 'train/data?sync=False' \n",
    "#print(f'**** POST {url}')\n",
    "response = requests.post(headers={'Authorization' : 'Bearer ' + API_TOKEN} , url=url)\n",
    "if response.status_code == 200:\n",
    "    train_url = response.text\n",
    "    url = train_url  + \"check_status\"\n",
    "    status = 'Running'\n",
    "    while (status == 'Running'):\n",
    "        #print(f'**** GET {url} ')\n",
    "        response = requests.get(headers={'Authorization' : 'Bearer ' + API_TOKEN} , url=url)\n",
    "        if response.status_code == 200:\n",
    "            status = response.text\n",
    "            print(f'<< Status: {status}')\n",
    "        else:\n",
    "            #print(f'<< response_code_cs {response.status_code}')\n",
    "            #print(f'<< response_text_cs {response.text}')\n",
    "            raise Exception(f'<< train failed; response_code {response.status_code}')\n",
    "        time.sleep(5)\n",
    "    url = train_url  + \"get_results\"\n",
    "    #print(f'**** GET {url}')\n",
    "    response = requests.get(headers={'Authorization' : 'Bearer ' + API_TOKEN}, url=url)\n",
    "    if response.status_code == 200:\n",
    "        trained_model_buffer = response.content\n",
    "        #print('<<<< Leaving server_predict()')\n",
    "        if (status != 'Completed'):\n",
    "            #print(f'<< response_code {response.status_code}')\n",
    "            #print(f'<< message {response.text}')\n",
    "            raise Exception(f'<< train failed; response_code {response.status_code}')\n",
    "    else:\n",
    "        #print(f'<< response_code {response.status_code}')\n",
    "        #print(f'<< message {response.text}')\n",
    "        raise Exception(f'<< train failed; response_code {response.status_code}')\n",
    "else:\n",
    "    #print(f'<< response_code {response.status_code}')\n",
    "    #print(f'<< message {response.text}')\n",
    "    raise Exception(f'<< train failed; response_code {response.status_code}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "url = model_url  + 'get_encrypted_model'\n",
    "print(f'**** GET {url}')\n",
    "response = requests.get(headers={'Authorization' : 'Bearer ' + API_TOKEN}, url=url)\n",
    "status_code = response.status_code\n",
    "print(f'>> response: {status_code}')\n",
    "if status_code == 200 and response.content:\n",
    "    model_buffer = response.content\n",
    "else:\n",
    "    print(f'<<<< response_code {response.status_code}')\n",
    "    print(f'<< message {response.text}')\n",
    "    raise Exception(f'<< client_decrypt_model failed; response_code {response.status_code}')\n",
    "\n",
    "enc_model = pyhelayers.load_he_model(client_context, model_buffer)     \n",
    "trained_plain = enc_model.decrypt_decode()\n",
    "print(f'<<<< encrypted model loaded')\n",
    "\n",
    "print('Predictions loaded and decrypted.')\n",
    "print(trained_plain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plain_predictions = trained_plain.predict([plain_samples])[0]\n",
    "plain_predictions = plain_predictions.reshape(plain_predictions.shape[0], 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 12. Unregister User\n",
    "User can unregister from the ML Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = model_url  + 'application/unregister_user'\n",
    "print(f'**** DELETE {url}')\n",
    "response = requests.delete(headers={'Authorization' : 'Bearer ' + API_TOKEN}, url=url)\n",
    "response.raise_for_status()\n",
    "print(f'Response code: {response.status_code} message: {response.text}')\n",
    "print('<< successfully unregistered user.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 13. Undeploy Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# undeploy medel url\n",
    "url = f'{API_URL}/{model_name}/{model_version}/undeploy_model'\n",
    "print(f'**** DELETE {url}')\n",
    "response = requests.delete(headers={'Authorization' : 'Bearer ' + API_TOKEN}, url=url)\n",
    "response.raise_for_status()\n",
    "print(f'Response code: {response.status_code} message: {response.text}')\n",
    "print('<< successfully undeployed model.')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
