{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "maritime-jumping",
   "metadata": {},
   "source": [
    "# Fruad Detection via XGBoost Classifier\n",
    "\n",
    "This notebook shows how to train and run an XGBoost model to identify fraud over encrypted data. The dataset is based on fraud detection <a href=\"https://www.kaggle.com/datasets/dssouvikganguly/application-datacsv\"> dataset</a>. This notebook uses the first 10 features of the dataset (5 numerical, 5 categorical), where the target field is a boolean indicating fraud ('1' is fraud)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "north-thickness",
   "metadata": {},
   "source": [
    "The dataset attributes are:\n",
    "\n",
    "|Attribute|Description|Values|\n",
    "|---|---|---|\n",
    "|SK_ID_CURR|Loan application ID|Integer (100000-500000)|\n",
    "|TARGET|The label|Categorial, 1 for fraud, 0 otherwise\n",
    "|NAME_CONTRACT_TYPE| The type of loan|Categorial, \"Cash loans\" or \"Revolving loans\"|\n",
    "|CODE_GENDER|The gender of the client|Categorial, 'M' for male, 'F' for Female|\n",
    "|FLAG_OWN_CAR|A boolean represents  if the client has car|Categorial, 'Y' for Yes, 'N' for no|\n",
    "|FLAG_OWN_REALTY|A boolean represents  if the client has realty|Categorial, 'Y' for Yes, 'N' for no|\n",
    "|CNT_CHILDREN|It represents the number of children a client has|Integer|\n",
    "|AMT_INCOME_TOTAL|Details on the requested loan|Numerical|\n",
    "|AMT_CREDIT|Details on the requested loan|Numerical|\n",
    "|AMT_ANNUITY|Details on the requested loan|Numerical|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fiscal-conducting",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "##### For reproducibility\n",
    "from numpy.random import seed\n",
    "seed_value= 1\n",
    "os.environ['PYTHONHASHSEED']=str(seed_value)\n",
    "seed(seed_value)\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import h5py\n",
    "\n",
    "import random\n",
    "import sklearn_json as skljson\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import sys\n",
    "from  preprocessor import Preprocessor\n",
    "TASK_NAME = \"fraud_detection_xgb\"\n",
    "run_with_gpu = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "structured-authorization",
   "metadata": {},
   "source": [
    "### Data loading\n",
    "Please refer to the dataset <a href=\"https://www.kaggle.com/datasets/dssouvikganguly/application-datacsv\">documentation</a> for the complete list of attributes and their description.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "documented-finger",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>SK_ID_CURR</th>\n",
       "      <th>TARGET</th>\n",
       "      <th>NAME_CONTRACT_TYPE</th>\n",
       "      <th>CODE_GENDER</th>\n",
       "      <th>FLAG_OWN_CAR</th>\n",
       "      <th>FLAG_OWN_REALTY</th>\n",
       "      <th>CNT_CHILDREN</th>\n",
       "      <th>AMT_INCOME_TOTAL</th>\n",
       "      <th>AMT_CREDIT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>100002</td>\n",
       "      <td>1</td>\n",
       "      <td>Cash loans</td>\n",
       "      <td>M</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>0</td>\n",
       "      <td>202500.0</td>\n",
       "      <td>406597.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>100003</td>\n",
       "      <td>0</td>\n",
       "      <td>Cash loans</td>\n",
       "      <td>F</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>0</td>\n",
       "      <td>270000.0</td>\n",
       "      <td>1293502.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>100004</td>\n",
       "      <td>0</td>\n",
       "      <td>Revolving loans</td>\n",
       "      <td>M</td>\n",
       "      <td>Y</td>\n",
       "      <td>Y</td>\n",
       "      <td>0</td>\n",
       "      <td>67500.0</td>\n",
       "      <td>135000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>100006</td>\n",
       "      <td>0</td>\n",
       "      <td>Cash loans</td>\n",
       "      <td>F</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>0</td>\n",
       "      <td>135000.0</td>\n",
       "      <td>312682.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>100007</td>\n",
       "      <td>0</td>\n",
       "      <td>Cash loans</td>\n",
       "      <td>M</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>0</td>\n",
       "      <td>121500.0</td>\n",
       "      <td>513000.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  SK_ID_CURR  TARGET NAME_CONTRACT_TYPE CODE_GENDER FLAG_OWN_CAR  \\\n",
       "0           0      100002       1         Cash loans           M            N   \n",
       "1           1      100003       0         Cash loans           F            N   \n",
       "2           2      100004       0    Revolving loans           M            Y   \n",
       "3           3      100006       0         Cash loans           F            N   \n",
       "4           4      100007       0         Cash loans           M            N   \n",
       "\n",
       "  FLAG_OWN_REALTY  CNT_CHILDREN  AMT_INCOME_TOTAL  AMT_CREDIT  \n",
       "0               Y             0          202500.0    406597.5  \n",
       "1               N             0          270000.0   1293502.5  \n",
       "2               Y             0           67500.0    135000.0  \n",
       "3               Y             0          135000.0    312682.5  \n",
       "4               Y             0          121500.0    513000.0  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"./datasets/fraud_detection.csv\")\n",
    "df = df.iloc[0:100000,0:10]\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "interracial-region",
   "metadata": {},
   "source": [
    "### Data preprocessing\n",
    "\n",
    "We first convert the categorial features (in the table below) to indicator vectors. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "banned-microphone",
   "metadata": {},
   "source": [
    "Subsequently, we split every row into its target value (y) and predicates (X)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "analyzed-arcade",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Unnamed: 0  SK_ID_CURR NAME_CONTRACT_TYPE CODE_GENDER FLAG_OWN_CAR  \\\n",
      "55821       55821      164672    Revolving loans           M            Y   \n",
      "11221       11221      113076         Cash loans           F            Y   \n",
      "64183       64183      174426         Cash loans           M            Y   \n",
      "11816       11816      113768         Cash loans           F            N   \n",
      "24857       24857      128908         Cash loans           M            N   \n",
      "...           ...         ...                ...         ...          ...   \n",
      "22576       22576      126272         Cash loans           M            N   \n",
      "42402       42402      149081         Cash loans           F            Y   \n",
      "31898       31898      136997         Cash loans           F            N   \n",
      "15103       15103      117637         Cash loans           F            N   \n",
      "21576       21576      125130         Cash loans           M            Y   \n",
      "\n",
      "      FLAG_OWN_REALTY  CNT_CHILDREN  AMT_INCOME_TOTAL  AMT_CREDIT  \n",
      "55821               Y             0          112500.0    180000.0  \n",
      "11221               Y             0          157500.0    284400.0  \n",
      "64183               N             0          427500.0    906228.0  \n",
      "11816               N             1           58500.0    113760.0  \n",
      "24857               Y             0          135000.0    348264.0  \n",
      "...               ...           ...               ...         ...  \n",
      "22576               Y             0          157500.0    254700.0  \n",
      "42402               Y             1          112500.0    835380.0  \n",
      "31898               N             0           81000.0    549882.0  \n",
      "15103               Y             0          135000.0    425133.0  \n",
      "21576               N             2          103500.0    355536.0  \n",
      "\n",
      "[14716 rows x 9 columns]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "train, test = train_test_split(df, test_size=0.2)\n",
    "y_train = train[\"TARGET\"]\n",
    "y_test = test[\"TARGET\"]\n",
    "x_train = train.drop(\"TARGET\",axis=1)\n",
    "x_test = test.drop(\"TARGET\",axis=1)\n",
    "print(x_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pleased-antigua",
   "metadata": {},
   "source": [
    "### Data preprocessing\n",
    "\n",
    "We split the dataset into the training (x_train, y_train) and test (x_test, y_test) sets and scale their features. \n",
    "\n",
    "We convert the categorial features (in the table below) to indicator vectors. \n",
    "\n",
    "Subsequently, we split the test set into test and validation sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "brilliant-tackle",
   "metadata": {},
   "outputs": [],
   "source": [
    "prep = Preprocessor()\n",
    "x_train = prep.fit_transform(x_train)\n",
    "x_test = prep.transform(x_test)\n",
    "\n",
    "x_test, x_val, y_test, y_val = train_test_split(x_test, y_test, test_size=4096, random_state=5, stratify=y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "latest-salmon",
   "metadata": {},
   "source": [
    "For later use in HE, we save the different preprocessed datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "involved-dressing",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving x_test of shape (10620, 9) in ./datasets/x_test.h5\n",
      "Saving y_test of shape (10620,) in ./datasets/x_test.h5\n",
      "Saving x_train of shape (58863, 9) in ./datasets/x_train.h5\n",
      "Saving y_train of shape (58863,) in ./datasets/x_train.h5\n",
      "Saving x_val of shape (4096, 9) in ./datasets/x_val.h5\n",
      "Saving y_val of shape (4096,) in ./datasets/x_val.h5\n"
     ]
    }
   ],
   "source": [
    "def save_data_set(x, y, data_type, path, s=''):\n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path)\n",
    "    fname=os.path.join(path, f'x_{data_type}{s}.h5')\n",
    "    print(\"Saving x_{} of shape {} in {}\".format(data_type, x.shape, fname))\n",
    "    xf = h5py.File(fname, 'w')\n",
    "    xf.create_dataset('x_{}'.format(data_type), data=x)\n",
    "    xf.close()\n",
    "\n",
    "    print(\"Saving y_{} of shape {} in {}\".format(data_type, y.shape, fname))\n",
    "    yf = h5py.File(os.path.join(path, f'y_{data_type}{s}.h5'), 'w')\n",
    "    yf.create_dataset(f'y_{data_type}', data=y)\n",
    "    yf.close()\n",
    "\n",
    "datasets_dir = \"./datasets/\"\n",
    "model_dir = \"./model/\"\n",
    "\n",
    "save_data_set(x_test, y_test, data_type='test', path=datasets_dir)\n",
    "save_data_set(x_train, y_train, data_type='train', path=datasets_dir)\n",
    "save_data_set(x_val, y_val, data_type='val', path=datasets_dir)\n",
    "\n",
    "if not os.path.exists(model_dir):\n",
    "    os.mkdir(model_dir)\n",
    "prep.save(os.path.join(model_dir, \"prep.pickle\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e5c3a5e",
   "metadata": {},
   "source": [
    "### Training a XGBoost Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "individual-layer",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xgb model ready\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "clf = XGBClassifier(eta=0.2, gamma=3.6, max_depth=3,scale_pos_weight =10, min_child_weight=3, subsample=0.8, objective=\"binary:logistic\", eval_metric = \"aucpr\", n_estimators=5)\n",
    "clf.fit(x_train, y_train)\n",
    "\n",
    "print('xgb model ready')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6ce5c47",
   "metadata": {},
   "source": [
    "For later use in HE, we save the trained model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8f6b171f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model to  ./model/fraud_detection_xgb_model.json\n"
     ]
    }
   ],
   "source": [
    "def save_model(model, path):\n",
    "    if not os.path.exists(path):\n",
    "        os.mkdir(path)\n",
    "    fname = os.path.join(path, f\"{TASK_NAME}_model.json\")\n",
    "    model.save_model(fname)\n",
    "    #skljson.to_json(model, fname)\n",
    "    print(\"Saved model to \",fname)\n",
    "\n",
    "save_model(clf, model_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27a38f9f",
   "metadata": {},
   "source": [
    "### Using the model for classifying cleartest data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "462437a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = clf.predict(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "872d294c",
   "metadata": {},
   "source": [
    "Confusion Matrix - TEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "128a8651",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC Score: 0.592\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.74      0.82      9754\n",
      "           1       0.13      0.45      0.20       866\n",
      "\n",
      "    accuracy                           0.71     10620\n",
      "   macro avg       0.53      0.59      0.51     10620\n",
      "weighted avg       0.87      0.71      0.77     10620\n",
      "\n",
      "Confusion Matrix:\n",
      "[[7173 2581]\n",
      " [ 477  389]]\n"
     ]
    }
   ],
   "source": [
    "f,t,thresholds = metrics.roc_curve(y_test, y_pred)\n",
    "cm = metrics.confusion_matrix(y_test, y_pred)\n",
    "print(f\"AUC Score: {metrics.auc(f,t):.3f}\")\n",
    "print(\"Classification report:\")\n",
    "print(metrics.classification_report(y_test, y_pred))\n",
    "print(\"Confusion Matrix:\")\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7484df37",
   "metadata": {},
   "source": [
    "### Using the model for classifying encrypted data\n",
    "\n",
    "To run the model over encrypted samples with homomorphic encryption (HE), we first load the pyhelayers package and refer it to the directory \"output/\", where we saved the model and the relevant datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8955e913",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyhelayers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e86ffef",
   "metadata": {},
   "source": [
    "Load test data and labels from the h5 file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "63b16121",
   "metadata": {},
   "outputs": [],
   "source": [
    "with h5py.File(datasets_dir + \"x_test.h5\") as f:\n",
    "    x_test = np.array(f[\"x_test\"])\n",
    "with h5py.File(datasets_dir + \"y_test.h5\") as f:\n",
    "    y_test = np.array(f[\"y_test\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34a9af7e-8f38-4f79-af31-06d214f74e16",
   "metadata": {},
   "source": [
    "### Compute the feature ranges\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d049504-d324-4214-8c14-86a032122304",
   "metadata": {},
   "source": [
    "Our implementaiton requires the users to specify the minimum and maximum values of each feature. Here, we extract this info from the training data and assume it will also be relevant to the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "63993415-b48c-4f73-b85b-57a9d0d728b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_feature_range(col):\n",
    "    return (col.min(), col.max())\n",
    "\n",
    "feature_ranges = []\n",
    "for col in x_train.T:\n",
    "    feature_ranges.append(get_feature_range(col))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b76c1f7f",
   "metadata": {},
   "source": [
    "Load a plain model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "967730dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded plain model\n"
     ]
    }
   ],
   "source": [
    "hyper_params = pyhelayers.PlainModelHyperParams()\n",
    "hyper_params.feature_ranges = feature_ranges\n",
    "# hyper_params.grep = 3\n",
    "# hyper_params.frep = 1\n",
    "hyper_params.verbose = False\n",
    "\n",
    "plain_xgb = pyhelayers.PlainModel.create(hyper_params, [os.path.join(model_dir, f\"{TASK_NAME}_model.json\")]) \n",
    "print(\"loaded plain model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad8ce704",
   "metadata": {},
   "source": [
    "Apply automatic optimziations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c737ab88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using SEAL backend\n"
     ]
    }
   ],
   "source": [
    "he_run_req = pyhelayers.HeRunRequirements()\n",
    "if hasattr(pyhelayers, \"HeaanContext\"):\n",
    "    print('Using HEaaN backend')\n",
    "    he_run_req.set_he_context_options([pyhelayers.HeaanContext()])\n",
    "else:\n",
    "    print('Using SEAL backend')\n",
    "    he_run_req.set_he_context_options([pyhelayers.SealCkksContext()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "8e972843",
   "metadata": {},
   "outputs": [],
   "source": [
    "profile = pyhelayers.HeModel.compile(plain_xgb, he_run_req)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b95f1d7f",
   "metadata": {},
   "source": [
    "Intialize the HE context with the optimized configuration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "08535539",
   "metadata": {},
   "outputs": [],
   "source": [
    "he_context = pyhelayers.HeModel.create_context(profile)\n",
    "if run_with_gpu:\n",
    "    he_context.set_default_device(pyhelayers.DeviceType.DEVICE_GPU)\n",
    "else:\n",
    "    he_context.set_default_device(pyhelayers.DeviceType.DEVICE_CPU)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a46de7e6",
   "metadata": {},
   "source": [
    "### 2.6. Initialize and encrypt the modelÂ¶\n",
    "We initialize the HE model using the plain model and the HE profile computed above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ee21a567",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FHE model encrypted and initialized\n"
     ]
    }
   ],
   "source": [
    "xgb = plain_xgb.get_empty_he_model(he_context)\n",
    "xgb.encode_encrypt(plain_xgb, profile)\n",
    "print('FHE model encrypted and initialized')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc83ecdb",
   "metadata": {},
   "source": [
    "We use the encrypted model over batches of 16 records at a time. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "1fdb16b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size=16\n",
    "plain_samples = x_test.take(indices=range(0, batch_size), axis=0)\n",
    "labels = y_test.take(indices=range(0, batch_size), axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fa10a46",
   "metadata": {},
   "source": [
    "Encrypt input samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "a681cba4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input data encrypted\n"
     ]
    }
   ],
   "source": [
    "iop = xgb.create_io_processor()\n",
    "x_test_enc = iop.encode_encrypt_input_for_predict(plain_samples)\n",
    "print('input data encrypted')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e328943-78c2-4141-aad7-846ffc898406",
   "metadata": {},
   "source": [
    "We perform FHE prediction on the encrypted test samples, using the encrypted model. The resulting predictions are encrypted as well, and will next be decrypted and compared to the expected labels."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e83a5b6a",
   "metadata": {},
   "source": [
    "### Run prediction over the encrypted data\n",
    "Now we perform inference of the 16 samples under encryption "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "b89a5d06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prediction ready\n"
     ]
    }
   ],
   "source": [
    "res = xgb.predict(x_test_enc)\n",
    "print('prediction ready')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50c08b17",
   "metadata": {},
   "source": [
    "### Plaintext results\n",
    "\n",
    "Decrypting the final results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "f1318a18",
   "metadata": {},
   "outputs": [],
   "source": [
    "res_plain = iop.decrypt_decode_output(res)\n",
    "res_plain = np.where(res_plain > 0.0, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "6316599f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "classification results\n",
      "=========================================\n",
      "Label: Bad., Prediction: Bad\n",
      "Label: Bad., Prediction: Bad\n",
      "Label: Bad., Prediction: Bad\n",
      "Label: Bad., Prediction: Good.\n",
      "Label: Bad., Prediction: Bad\n",
      "Label: Bad., Prediction: Good.\n",
      "Label: Bad., Prediction: Bad\n",
      "Label: Bad., Prediction: Bad\n",
      "Label: Bad., Prediction: Good.\n",
      "Label: Bad., Prediction: Bad\n",
      "Label: Bad., Prediction: Good.\n",
      "Label: Bad., Prediction: Good.\n",
      "Label: Good, Prediction: Bad\n",
      "Label: Bad., Prediction: Bad\n",
      "Label: Bad., Prediction: Good.\n",
      "Label: Bad., Prediction: Bad\n"
     ]
    }
   ],
   "source": [
    "print('\\nclassification results')\n",
    "print('=========================================')\n",
    "for label,pred in zip(labels,res_plain):\n",
    "    print('Label:',('Good' if label==1 else 'Bad.'),end=', ')\n",
    "    print('Prediction:',('Bad' if pred[0]<0.5 else 'Good.'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04c39359-5c1a-4963-99e5-667cb20be6b5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 ('fhe-py38-env')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "f497b8fb6983b2b7e8d6051f4315e544585546557ee2f98a631c292ad437c819"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
