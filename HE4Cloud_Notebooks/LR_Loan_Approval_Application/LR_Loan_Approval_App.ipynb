{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "maritime-jumping",
   "metadata": {},
   "source": [
    "# Loan aproval analysis using a fabricated German Credit Data dataset\n",
    "\n",
    "This notebook shows an example of training and running a model that classifies people described by a set of attributes as good or bad credit risks.\n",
    "It is based on a fabricated dataset that generated based on the <a href=\"https://archive.ics.uci.edu/ml/datasets/statlog+(german+credit+data)\">German Credit Data dataset</a> from the <a href=\"https://archive.ics.uci.edu/\">UCI</a> repository. \n",
    "The German Credit Data dataset has 20 attributes (7 numerical, 13 categorical) and the target field is an integer either Good (1) or Bad (2), where it is worse to class a customer as good when they are bad (5), than it is to class a customer as bad when they are good (1).\n",
    "\n",
    "The demonstration uses a logistic regression model for classification.\n",
    "\n",
    "The required estimated memory is: model (140MB), input (7.34MB), output (0.26MB), and context (100MB).\n",
    "\n",
    "We start by importing the required source packages."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "north-thickness",
   "metadata": {},
   "source": [
    "The dataset attributes are:\n",
    "\n",
    "|Attribute|Description|Values|\n",
    "|---|---|---|\n",
    "|checking|Status of existing checking account|<ul><li> A11 : ... < 0 DM</li></ul><ul><li> A12 : 0 <= ... <  200 DM</li></ul><ul><li>A13 :      ... >= 200 DM / salary assignments for at least 1 year</li></ul><ul><li>A14 : no checking account</li></ul>|\n",
    "|duration|Duration in month| Numerical\n",
    "|credit-hist|Credit history|<ul><li>A30 : no credits taken/all credits paid back duly</li></ul><ul><li>A31 : all credits at this bank paid back duly</li></ul><ul><li>A32 : existing credits paid back duly till now</li></ul><ul><li>A33 : delay in paying off in the past</li></ul><ul><li>A34 : critical account/ other credits existing (not at this bank)</li></ul>|\n",
    "|purpose|Purpose|<ul><li>A40 : car (new)</li></ul><ul><li>A41 : car (used)</li></ul><ul><li>A42 : furniture/equipment</li></ul><ul><li>A43 : radio/television</li></ul><ul><li>A44 : domestic appliances</li></ul><ul><li>A45 : repairs</li></ul><ul><li>A46 : education</li></ul><ul><li>A47 : (vacation - does not exist?)</li></ul><ul><li>A48 : retraining</li></ul><ul><li>A49 : business</li></ul><ul><li>A410 : others</li></ul>|\n",
    "|credit-amount|Credit amount|Numerical|\n",
    "|saving-account|Savings account/bonds|<ul><li>A61 :          ... <  100 DM</li></ul><ul><li>A62 :   100 <= ... <  500 DM</li></ul><ul><li>A63 :   500 <= ... < 1000 DM</li></ul><ul><li>A64 :          .. >= 1000 DM</li></ul><ul><li>A65 :   unknown/ no savings account</li></ul>|\n",
    "|employment-duration|Present employment since|<ul><li>A71 : unemployed</li></ul><ul><li>A72 :       ... < 1 year</li></ul><ul><li>A73 : 1  <= ... < 4 years</li></ul><ul><li>A74 : 4  <= ... < 7 years</li></ul><ul><li>A75 :       .. >= 7 years|\n",
    "|installment-income-ratio|Installment rate in percentage of disposable income|Numerical|\n",
    "|Attribute 9: (qualitative)\n",
    "|sex|Personal status and sex|<ul><li>A91 : male : divorced/separated</li></ul><ul><li>A92 : female : divorced/separated/married</li></ul><ul><li>A93 : male : single</li></ul><ul><li>A94 : male : married/widowed</li></ul><ul><li>A95 : female : single</li></ul>|\n",
    "|debtors-guarantors|Other debtors / guarantors|<ul><li>A101 : none</li></ul><ul><li>A102 : co-applicant</li></ul><ul><li>A103 : guarantor|\n",
    "|residence-since|Present residence since|Numerical|\n",
    "|property|Property|<ul><li>A121 : real estate</li></ul><ul><li>A122 : if not A121 : building society savings agreement/life insurance</li></ul><ul><li>A123 : if not A121/A122 : car or other, not in attribute 6</li></ul><ul><li>A124 : unknown / no property</li></ul>|\n",
    "|age|Age in years| Numerical|\n",
    "|installment-plans|Other installment plans|<ul><li>A141 : bank</li></ul><ul><li>A142 : stores</li></ul><ul><li>A143 : none</li></ul>|\n",
    "|housing|Housing|<ul><li>A151 : rent</li></ul><ul><li>A152 : own</li></ul><ul><li>A153 : for free</li></ul>|\n",
    "|num-existing-credits|Number of existing credits at this bank|Numerical|\n",
    "|job|Job|<ul><li>A171 : unemployed/ unskilled  - non-resident</li></ul><ul><li>A172 : unskilled - resident</li></ul><ul><li>A173 : skilled employee / official</li></ul><ul><li>A174 : management/ self-employed/</li></ul><ul><li>highly qualified employee/ officer|\n",
    "|num-liable|Number of people being liable to provide maintenance for|Numerical|\n",
    "|telephone|Telephone|<ul><li>A191 : none</li></ul><ul><li>A192 : yes, registered under the customers name</li></ul>|\n",
    "|foreighn-worker|foreign worker|<ul><li>A201 : yes</li></ul><ul><li>A202 : no</li></ul>|\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fiscal-conducting",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "##### For reproducibility\n",
    "from numpy.random import seed\n",
    "seed_value= 1\n",
    "os.environ['PYTHONHASHSEED']=str(seed_value)\n",
    "seed(seed_value)\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import h5py\n",
    "\n",
    "\n",
    "import random\n",
    "import sklearn_json as skljson\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import sys\n",
    "from  preprocessor import Preprocessor\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "structured-authorization",
   "metadata": {},
   "source": [
    "### Data loading\n",
    "Please refer to the dataset <a href=\"https://archive.ics.uci.edu/ml/datasets/statlog+(german+credit+data)\">documentation</a> for the complete list of attributes and their description."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "documented-finger",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = {'checking':str, \n",
    "        'duration':np.int64, \n",
    "        'credit-hist':str, \n",
    "        'purpose':str, \n",
    "        'credit-amount':np.int64,\n",
    "        'savings-account':str, \n",
    "        'employment-duration':str, \n",
    "        'installment-income-ratio':np.int64,\n",
    "        'marital-gender-status':str,\n",
    "        'debtors-guarantors':str, \n",
    "        'residence-since':str, \n",
    "        'property':str, \n",
    "        'age':np.int64,\n",
    "        'installment-plans':str, \n",
    "        'housing':str, \n",
    "        'num-existing-credits':np.int64, \n",
    "        'job':str,\n",
    "        'num-liable':np.int64, \n",
    "        'telephone':str, \n",
    "        'foreign-worker':str, \n",
    "        'is_good':np.int64}\n",
    "\n",
    "df = pd.read_csv('./datasets/loan_approval.generated', sep=\" \", index_col=False, names=cols.keys(), header=None, dtype=cols)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "interracial-region",
   "metadata": {},
   "source": [
    "### Data preprocessing\n",
    "\n",
    "We first convert the categorial features (in the table below) to indicator vectors. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "banned-microphone",
   "metadata": {},
   "source": [
    "Subsequently, we split every row into its target value (y) and predicates (X)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "analyzed-arcade",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(['is_good'], axis=1)\n",
    "y = df['is_good'].replace([1, 2], [1, 0])\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pleased-antigua",
   "metadata": {},
   "source": [
    "### Data preprocessing\n",
    "\n",
    "We split the dataset into the training (x_train, y_train) and test (x_test, y_test) sets and scale their features. \n",
    "\n",
    "We convert the categorial features (in the table below) to indicator vectors. \n",
    "\n",
    "Subsequently, we split the test set into test and validation sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "brilliant-tackle",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(X, y ,test_size=0.2, random_state=5, stratify=y)\n",
    "\n",
    "prep = Preprocessor()\n",
    "x_train = prep.fit_transform(x_train)\n",
    "x_test = prep.transform(x_test)\n",
    "\n",
    "x_test, x_val, y_test, y_val = train_test_split(x_test, y_test, test_size=4096, random_state=5, stratify=y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "latest-salmon",
   "metadata": {},
   "source": [
    "For later use in HE, we save the different preprocessed datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "involved-dressing",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_data_set(x, y, data_type, path, s=''):\n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path)\n",
    "    fname=os.path.join(path, f'x_{data_type}{s}.h5')\n",
    "    print(\"Saving x_{} of shape {} in {}\".format(data_type, x.shape, fname))\n",
    "    xf = h5py.File(fname, 'w')\n",
    "    xf.create_dataset('x_{}'.format(data_type), data=x)\n",
    "    xf.close()\n",
    "\n",
    "    print(\"Saving y_{} of shape {} in {}\".format(data_type, y.shape, fname))\n",
    "    yf = h5py.File(os.path.join(path, f'y_{data_type}{s}.h5'), 'w')\n",
    "    yf.create_dataset(f'y_{data_type}', data=y)\n",
    "    yf.close()\n",
    "\n",
    "datasets_dir = \"datasets/\"\n",
    "model_dir = \"model/\"\n",
    "\n",
    "save_data_set(x_test, y_test, data_type='test', path=datasets_dir)\n",
    "save_data_set(x_train, y_train, data_type='train', path=datasets_dir)\n",
    "save_data_set(x_val, y_val, data_type='val', path=datasets_dir)\n",
    "\n",
    "\n",
    "prep.save(os.path.join(model_dir, \"prep.pickle\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e5c3a5e",
   "metadata": {},
   "source": [
    "### Logistic Regression Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "individual-layer",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegression(C=0.1)\n",
    "lr.fit(x_train, y_train)\n",
    "\n",
    "print('LR model ready')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6ce5c47",
   "metadata": {},
   "source": [
    "For later use in HE, we save the trained model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f6b171f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(model, path):\n",
    "    if not os.path.exists(path):\n",
    "        os.mkdir(path)\n",
    "    fname = os.path.join(path, \"lr_loan_approval_model.json\")\n",
    "    skljson.to_json(model, fname)\n",
    "    print(\"Saved model to \",fname)\n",
    "\n",
    "save_model(lr, model_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27a38f9f",
   "metadata": {},
   "source": [
    "### Using the model for classifying cleartest data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "462437a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = lr.predict(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "872d294c",
   "metadata": {},
   "source": [
    "Confusion Matrix - TEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "128a8651",
   "metadata": {},
   "outputs": [],
   "source": [
    "f,t,thresholds = metrics.roc_curve(y_test, y_pred)\n",
    "cm = metrics.confusion_matrix(y_test, y_pred)\n",
    "print(f\"AUC Score: {metrics.auc(f,t):.3f}\")\n",
    "print(\"Classification report:\")\n",
    "print(metrics.classification_report(y_test, y_pred))\n",
    "print(\"Confusion Matrix:\")\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7484df37",
   "metadata": {},
   "source": [
    "### Using the model for classifying encrypted data\n",
    "\n",
    "To run the model over encrypted samples with homomorphic encryption (HE), we first load the pyhelayers package and refer it to the directory \"output/\", where we saved the model and the relevant datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8955e913",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyhelayers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e86ffef",
   "metadata": {},
   "source": [
    "Load test data and labels from the h5 file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63b16121",
   "metadata": {},
   "outputs": [],
   "source": [
    "with h5py.File(datasets_dir + \"x_test.h5\") as f:\n",
    "    x_test = np.array(f[\"x_test\"])\n",
    "with h5py.File(datasets_dir + \"y_test.h5\") as f:\n",
    "    y_test = np.array(f[\"y_test\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b76c1f7f",
   "metadata": {},
   "source": [
    "Load a plain model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "967730dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "lrp = pyhelayers.LogisticRegressionPlain()\n",
    "lrp.init_from_json_file(model_dir + \"lr_loan_approval_model.json\")\n",
    "print(\"loaded plain model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d74edab",
   "metadata": {},
   "source": [
    "Use a 3rd degree polynomial to approximate the sigmoid activation of the LogisticRegression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd2388bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "lrp.set_activation(pyhelayers.LRActivation.SIGMOID_POLY_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad8ce704",
   "metadata": {},
   "source": [
    "Apply automatic optimziations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c737ab88",
   "metadata": {},
   "outputs": [],
   "source": [
    "context = pyhelayers.DefaultContext()\n",
    "optimizer = pyhelayers.HeProfileOptimizer(lrp, context)\n",
    "optimizer.get_requirements().set_batch_size(16)\n",
    "profile = optimizer.get_optimized_profile(False)\n",
    "batch_size = profile.get_batch_size()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94df2d49",
   "metadata": {},
   "source": [
    "To reduce the memory requirements of the context, we reduce the number of rotation keys."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e972843",
   "metadata": {},
   "outputs": [],
   "source": [
    "pf1=pyhelayers.PublicFunctions()\n",
    "pf1.rotate=pyhelayers.RotationSetType.CUSTOM_ROTATIONS\n",
    "pf1.set_rotation_steps([1,4,16,128])\n",
    "pf1.conjugate=True\n",
    "requirements = profile.requirement\n",
    "requirements.public_functions=pf1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b95f1d7f",
   "metadata": {},
   "source": [
    "Intialize the HE context with the optimized configuration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08535539",
   "metadata": {},
   "outputs": [],
   "source": [
    "context.init(profile.requirement)\n",
    "print('HE Context ready. Batch size=',batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a46de7e6",
   "metadata": {},
   "source": [
    "Print the HE context (w/ keys) size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee21a567",
   "metadata": {},
   "outputs": [],
   "source": [
    "evalBuf=context.save_to_buffer();\n",
    "print('Size',len(evalBuf)/1024/1024,'MB')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb462d74",
   "metadata": {},
   "source": [
    "### Encrypt the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75dfa500",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = pyhelayers.LogisticRegression(context)\n",
    "lr.encode_encrypt(lrp, profile)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc83ecdb",
   "metadata": {},
   "source": [
    "We use the encrypted model over batches of 16 records at a time. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fdb16b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "plain_samples = x_test.take(indices=range(0, batch_size), axis=0)\n",
    "labels = y_test.take(indices=range(0, batch_size), axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fa10a46",
   "metadata": {},
   "source": [
    "Encrypt input samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a681cba4",
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = lr.encode_encrypt_input(plain_samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e83a5b6a",
   "metadata": {},
   "source": [
    "Now we perform inference of the 16 samples under encryption "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b89a5d06",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions=lr.predict(samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50c08b17",
   "metadata": {},
   "source": [
    "### Plaintext results\n",
    "\n",
    "Decrypting the final results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1318a18",
   "metadata": {},
   "outputs": [],
   "source": [
    "plain_predictions = lr.decrypt_decode_output(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6316599f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('\\nclassification results')\n",
    "print('=========================================')\n",
    "for label,pred in zip(labels,plain_predictions):\n",
    "    print('Label:',('Good' if label==1 else 'Bad.'),end=', ')\n",
    "    print('Prediction:',('Bad' if pred[0]<0.5 else 'Good.'))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "88da8e93a7ed8632a00f934738de6497ab10b6ac9a993714594378cc411356f5"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 ('ramy-env3.8')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
