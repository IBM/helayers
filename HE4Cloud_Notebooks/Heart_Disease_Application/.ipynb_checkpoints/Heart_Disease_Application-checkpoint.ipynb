{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Heart disease example\n",
    "\n",
    "This notebook shows an example of training and running a model that classifies heart diseases.\n",
    "It is based on the <a herf=\"https://archive.ics.uci.edu/ml/datasets/Heart+Disease\">Heart Disease dataset</a> from the <a href=\"https://archive.ics.uci.edu/\">UCI</a> repository. For privacy reasons, names and social security numbers (SSNs) of patients were removed from the dataset, and were replaced with dummy values.\n",
    "\n",
    "Following the UCI description, this demonstration only uses 14 attributes out of the 76 attributes listed to predict whether a patient will have a heart attack. The target field is an integer value from 0 (no attack) to 4.\n",
    "\n",
    "The demonstration uses a 3 layer neural network (NN): FC(50) --> Square activation --> FC(1)\n",
    "\n",
    "The required estimated memory is: model (4.46MB), input (3.67MB), output (0.13MB), and context (8.18MB).\n",
    "\n",
    "We start by importing the required source packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-14 16:55:29.334223: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-04-14 16:55:29.334282: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "Error in sys.excepthook:\n",
      "Traceback (most recent call last):\n",
      "  File \"/data/fhe/python/akram-env/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 1934, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'RuntimeError' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/data/fhe/python/akram-env/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 1936, in showtraceback\n",
      "    stb = self.InteractiveTB.structured_traceback(etype,\n",
      "  File \"/data/fhe/python/akram-env/lib/python3.8/site-packages/IPython/core/ultratb.py\", line 1105, in structured_traceback\n",
      "    return FormattedTB.structured_traceback(\n",
      "  File \"/data/fhe/python/akram-env/lib/python3.8/site-packages/IPython/core/ultratb.py\", line 999, in structured_traceback\n",
      "    return VerboseTB.structured_traceback(\n",
      "  File \"/data/fhe/python/akram-env/lib/python3.8/site-packages/IPython/core/ultratb.py\", line 851, in structured_traceback\n",
      "    assert etb is not None\n",
      "AssertionError\n",
      "\n",
      "Original exception was:\n",
      "RuntimeError: module compiled against API version 0xe but this version of numpy is 0xd\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "SystemError: <built-in method __contains__ of dict object at 0x7f01e948c980> returned a result with an error set",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m/data/bio/akram/Models/Heart_Disease_Application/Heart_Disease_Application.ipynb Cell 2'\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Blnx-mpc1-test.sl.cloud9.ibm.com/data/bio/akram/Models/Heart_Disease_Application/Heart_Disease_Application.ipynb#ch0000001vscode-remote?line=11'>12</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msklearn\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmodel_selection\u001b[39;00m \u001b[39mimport\u001b[39;00m train_test_split\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Blnx-mpc1-test.sl.cloud9.ibm.com/data/bio/akram/Models/Heart_Disease_Application/Heart_Disease_Application.ipynb#ch0000001vscode-remote?line=12'>13</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msklearn\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpreprocessing\u001b[39;00m \u001b[39mimport\u001b[39;00m MinMaxScaler\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2Blnx-mpc1-test.sl.cloud9.ibm.com/data/bio/akram/Models/Heart_Disease_Application/Heart_Disease_Application.ipynb#ch0000001vscode-remote?line=14'>15</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mtf\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Blnx-mpc1-test.sl.cloud9.ibm.com/data/bio/akram/Models/Heart_Disease_Application/Heart_Disease_Application.ipynb#ch0000001vscode-remote?line=15'>16</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m \u001b[39mimport\u001b[39;00m backend \u001b[39mas\u001b[39;00m K\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Blnx-mpc1-test.sl.cloud9.ibm.com/data/bio/akram/Models/Heart_Disease_Application/Heart_Disease_Application.ipynb#ch0000001vscode-remote?line=16'>17</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m \u001b[39mimport\u001b[39;00m utils, callbacks, losses\n",
      "File \u001b[0;32m/data/fhe/python/akram-env/lib/python3.8/site-packages/tensorflow/__init__.py:37\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     <a href='file:///data/fhe/python/akram-env/lib/python3.8/site-packages/tensorflow/__init__.py?line=33'>34</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39msys\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39m_sys\u001b[39;00m\n\u001b[1;32m     <a href='file:///data/fhe/python/akram-env/lib/python3.8/site-packages/tensorflow/__init__.py?line=34'>35</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtyping\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39m_typing\u001b[39;00m\n\u001b[0;32m---> <a href='file:///data/fhe/python/akram-env/lib/python3.8/site-packages/tensorflow/__init__.py?line=36'>37</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mtools\u001b[39;00m \u001b[39mimport\u001b[39;00m module_util \u001b[39mas\u001b[39;00m _module_util\n\u001b[1;32m     <a href='file:///data/fhe/python/akram-env/lib/python3.8/site-packages/tensorflow/__init__.py?line=37'>38</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutil\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mlazy_loader\u001b[39;00m \u001b[39mimport\u001b[39;00m LazyLoader \u001b[39mas\u001b[39;00m _LazyLoader\n\u001b[1;32m     <a href='file:///data/fhe/python/akram-env/lib/python3.8/site-packages/tensorflow/__init__.py?line=39'>40</a>\u001b[0m \u001b[39m# Make sure code inside the TensorFlow codebase can use tf2.enabled() at import.\u001b[39;00m\n",
      "File \u001b[0;32m/data/fhe/python/akram-env/lib/python3.8/site-packages/tensorflow/python/__init__.py:37\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     <a href='file:///data/fhe/python/akram-env/lib/python3.8/site-packages/tensorflow/python/__init__.py?line=28'>29</a>\u001b[0m \u001b[39m# We aim to keep this file minimal and ideally remove completely.\u001b[39;00m\n\u001b[1;32m     <a href='file:///data/fhe/python/akram-env/lib/python3.8/site-packages/tensorflow/python/__init__.py?line=29'>30</a>\u001b[0m \u001b[39m# If you are adding a new file with @tf_export decorators,\u001b[39;00m\n\u001b[1;32m     <a href='file:///data/fhe/python/akram-env/lib/python3.8/site-packages/tensorflow/python/__init__.py?line=30'>31</a>\u001b[0m \u001b[39m# import it in modules_with_exports.py instead.\u001b[39;00m\n\u001b[1;32m     <a href='file:///data/fhe/python/akram-env/lib/python3.8/site-packages/tensorflow/python/__init__.py?line=31'>32</a>\u001b[0m \n\u001b[1;32m     <a href='file:///data/fhe/python/akram-env/lib/python3.8/site-packages/tensorflow/python/__init__.py?line=32'>33</a>\u001b[0m \u001b[39m# go/tf-wildcard-import\u001b[39;00m\n\u001b[1;32m     <a href='file:///data/fhe/python/akram-env/lib/python3.8/site-packages/tensorflow/python/__init__.py?line=33'>34</a>\u001b[0m \u001b[39m# pylint: disable=wildcard-import,g-bad-import-order,g-import-not-at-top\u001b[39;00m\n\u001b[1;32m     <a href='file:///data/fhe/python/akram-env/lib/python3.8/site-packages/tensorflow/python/__init__.py?line=35'>36</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m \u001b[39mimport\u001b[39;00m pywrap_tensorflow \u001b[39mas\u001b[39;00m _pywrap_tensorflow\n\u001b[0;32m---> <a href='file:///data/fhe/python/akram-env/lib/python3.8/site-packages/tensorflow/python/__init__.py?line=36'>37</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39meager\u001b[39;00m \u001b[39mimport\u001b[39;00m context\n\u001b[1;32m     <a href='file:///data/fhe/python/akram-env/lib/python3.8/site-packages/tensorflow/python/__init__.py?line=38'>39</a>\u001b[0m \u001b[39m# pylint: enable=wildcard-import\u001b[39;00m\n\u001b[1;32m     <a href='file:///data/fhe/python/akram-env/lib/python3.8/site-packages/tensorflow/python/__init__.py?line=39'>40</a>\u001b[0m \n\u001b[1;32m     <a href='file:///data/fhe/python/akram-env/lib/python3.8/site-packages/tensorflow/python/__init__.py?line=40'>41</a>\u001b[0m \u001b[39m# Bring in subpackages.\u001b[39;00m\n\u001b[1;32m     <a href='file:///data/fhe/python/akram-env/lib/python3.8/site-packages/tensorflow/python/__init__.py?line=41'>42</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m \u001b[39mimport\u001b[39;00m data\n",
      "File \u001b[0;32m/data/fhe/python/akram-env/lib/python3.8/site-packages/tensorflow/python/eager/context.py:35\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     <a href='file:///data/fhe/python/akram-env/lib/python3.8/site-packages/tensorflow/python/eager/context.py?line=32'>33</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m \u001b[39mimport\u001b[39;00m pywrap_tfe\n\u001b[1;32m     <a href='file:///data/fhe/python/akram-env/lib/python3.8/site-packages/tensorflow/python/eager/context.py?line=33'>34</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m \u001b[39mimport\u001b[39;00m tf2\n\u001b[0;32m---> <a href='file:///data/fhe/python/akram-env/lib/python3.8/site-packages/tensorflow/python/eager/context.py?line=34'>35</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mclient\u001b[39;00m \u001b[39mimport\u001b[39;00m pywrap_tf_session\n\u001b[1;32m     <a href='file:///data/fhe/python/akram-env/lib/python3.8/site-packages/tensorflow/python/eager/context.py?line=35'>36</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39meager\u001b[39;00m \u001b[39mimport\u001b[39;00m executor\n\u001b[1;32m     <a href='file:///data/fhe/python/akram-env/lib/python3.8/site-packages/tensorflow/python/eager/context.py?line=36'>37</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39meager\u001b[39;00m \u001b[39mimport\u001b[39;00m monitoring\n",
      "File \u001b[0;32m/data/fhe/python/akram-env/lib/python3.8/site-packages/tensorflow/python/client/pywrap_tf_session.py:19\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     <a href='file:///data/fhe/python/akram-env/lib/python3.8/site-packages/tensorflow/python/client/pywrap_tf_session.py?line=16'>17</a>\u001b[0m \u001b[39m# pylint: disable=invalid-import-order,g-bad-import-order, wildcard-import, unused-import\u001b[39;00m\n\u001b[1;32m     <a href='file:///data/fhe/python/akram-env/lib/python3.8/site-packages/tensorflow/python/client/pywrap_tf_session.py?line=17'>18</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m \u001b[39mimport\u001b[39;00m pywrap_tensorflow\n\u001b[0;32m---> <a href='file:///data/fhe/python/akram-env/lib/python3.8/site-packages/tensorflow/python/client/pywrap_tf_session.py?line=18'>19</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mclient\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39m_pywrap_tf_session\u001b[39;00m \u001b[39mimport\u001b[39;00m \u001b[39m*\u001b[39m\n\u001b[1;32m     <a href='file:///data/fhe/python/akram-env/lib/python3.8/site-packages/tensorflow/python/client/pywrap_tf_session.py?line=19'>20</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mclient\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39m_pywrap_tf_session\u001b[39;00m \u001b[39mimport\u001b[39;00m _TF_SetTarget\n\u001b[1;32m     <a href='file:///data/fhe/python/akram-env/lib/python3.8/site-packages/tensorflow/python/client/pywrap_tf_session.py?line=20'>21</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mclient\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39m_pywrap_tf_session\u001b[39;00m \u001b[39mimport\u001b[39;00m _TF_SetConfig\n",
      "\u001b[0;31mImportError\u001b[0m: SystemError: <built-in method __contains__ of dict object at 0x7f01e948c980> returned a result with an error set"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from numpy.random import seed\n",
    "seed(1)\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import accuracy_score,confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "import tensorflow as tf\n",
    "from keras import backend as K\n",
    "from keras import utils, callbacks, losses\n",
    "from keras.layers import Dense, Activation\n",
    "from keras.models import Sequential\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from  preprocessor import Preprocessor\n",
    "\n",
    "import h5py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data loading\n",
    "Please refer to the dataset <a href=\"https://archive.ics.uci.edu/ml/datasets/Heart+Disease\">documentation</a> for the complete list of attributes and their description.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.8.10 64-bit' requires ipykernel package.\n",
      "Run the following command to install 'ipykernel' into the Python environment. \n",
      "Command: '/data/fhe/python/3.8/bin/python3.8 -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"datasets/heart_disease.csv\")\n",
    "\n",
    "df.rename(columns={'age': 'Age', 'sex': 'Sex', 'cp': 'Chest_pain', 'trestbps': 'Resting_blood_pressure',\n",
    "                       'chol': 'Cholesterol', 'fbs': 'Fasting_blood_sugar',\n",
    "                       'restecg': 'ECG_results', 'thalach': 'Maximum_heart_rate',\n",
    "                       'exang': 'Exercise_induced_angina', 'oldpeak': 'ST_depression', 'ca': 'Major_vessels',\n",
    "                       'thal': 'Thalassemia_types', 'target': 'Heart_attack', 'slope': 'ST_slope'}, inplace=True)\n",
    "\n",
    "print(f'data shape: {df.shape}')\n",
    "print(df.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data preprocessing\n",
    "\n",
    "We first convert the categorial features (in the table below) to indicator vectors. \n",
    "\n",
    "|Attributes|Description|Values|\n",
    "|---|---|---|\n",
    "|Chest_pain| The chest pain type | Typical angina (1), Atypical angina (2), Non-anginal pain (3), Asymptomatic (4)|\n",
    "|Thalassemia_types| | Normal (3), Fixed defect (6), Reversable defect (7)|\n",
    "|ECG_results| Resting electrocardiographic results|<ul><li>Normal (0)</li></ul><ul><li>Having ST-T wave abnormality (T wave inversions and/or ST elevation or depression of > 0.05 mV) (1)</li></ul><ul><li> Showing probable or definite left ventricular hypertrophy by Estes' criteria (2)</li></ul>|\n",
    "|ST_slope| The slope of the peak exercise ST segment| Upsloping (1), Flat (2), Downsloping (3)|\n",
    "|Major_vessels | The number of major vessels (0-3) colored by flourosopy | 0-3 |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.8.10 64-bit' requires ipykernel package.\n",
      "Run the following command to install 'ipykernel' into the Python environment. \n",
      "Command: '/data/fhe/python/3.8/bin/python3.8 -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "# dummy1 = pd.get_dummies(df.Chest_pain)\n",
    "# dummy2 = pd.get_dummies(df.Thalassemia_types)\n",
    "# dummy3 = pd.get_dummies(df.ECG_results)\n",
    "# dummy4 = pd.get_dummies(df.ST_slope)\n",
    "# dummy5 = pd.get_dummies(df.Major_vessels)\n",
    "# merge = pd.concat([df, dummy1, dummy2, dummy3, dummy4, dummy5], axis='columns')\n",
    "\n",
    "# final = merge.drop(['Chest_pain', 'Thalassemia_types', 'ECG_results', 'ST_slope', 'Major_vessels'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Subsequently, we split every row into its target value (y) and predicates (X)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.8.10 64-bit' requires ipykernel package.\n",
      "Run the following command to install 'ipykernel' into the Python environment. \n",
      "Command: '/data/fhe/python/3.8/bin/python3.8 -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "# X = final.drop(['Heart_attack'], axis=1)\n",
    "# y = final['Heart_attack']\n",
    "\n",
    "X = df\n",
    "y = df['Heart_attack']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We split the dataset into the training (x_train, y_train) and test (x_test, y_test) sets and scale their features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.8.10 64-bit' requires ipykernel package.\n",
      "Run the following command to install 'ipykernel' into the Python environment. \n",
      "Command: '/data/fhe/python/3.8/bin/python3.8 -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=5)\n",
    "\n",
    "# feature_scaler = MinMaxScaler()\n",
    "# x_train = feature_scaler.fit_transform(x_train)\n",
    "# x_test = feature_scaler.transform(x_test)\n",
    "\n",
    "prep = Preprocessor()\n",
    "x_train = prep.fit_transform(x_train)\n",
    "x_test = prep.transform(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we split the test set into test (x_test, y_test) and validation (x_val, y_val) sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.8.10 64-bit' requires ipykernel package.\n",
      "Run the following command to install 'ipykernel' into the Python environment. \n",
      "Command: '/data/fhe/python/3.8/bin/python3.8 -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "x_test, x_val, y_test, y_val = train_test_split(x_test, y_test, test_size=0.5, random_state=5)\n",
    "print(f\"y_test: {sum(y_test)}/{len(y_test)}\")\n",
    "print(f\"y_train: {sum(y_train)}/{len(y_train)}\")\n",
    "print(f\"y_val: {sum(y_val)}/{len(y_val)}\")\n",
    "input_shape = x_train.shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For later use in HE, we save the different preprocessed datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.8.10 64-bit' requires ipykernel package.\n",
      "Run the following command to install 'ipykernel' into the Python environment. \n",
      "Command: '/data/fhe/python/3.8/bin/python3.8 -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "def save_data_set(x, y, data_type, path, s=''):\n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path)\n",
    "    fname=os.path.join(path, f'x_{data_type}{s}.h5')\n",
    "    print(\"Saving x_{} of shape {} in {}\".format(data_type, x.shape, fname))\n",
    "    xf = h5py.File(fname, 'w')\n",
    "    xf.create_dataset('x_{}'.format(data_type), data=x)\n",
    "    xf.close()\n",
    "\n",
    "    print(\"Saving y_{} of shape {} in {}\".format(data_type, y.shape, fname))\n",
    "    yf = h5py.File(os.path.join(path, f'y_{data_type}{s}.h5'), 'w')\n",
    "    yf.create_dataset(f'y_{data_type}', data=y)\n",
    "    yf.close()\n",
    "\n",
    "input_output_dir = \"outputs/\"\n",
    "\n",
    "save_data_set(x_test, y_test, data_type='test', path=input_output_dir)\n",
    "save_data_set(x_train, y_train, data_type='train', path=input_output_dir)\n",
    "save_data_set(x_val, y_val, data_type='val', path=input_output_dir)\n",
    "\n",
    "prep.save(os.path.join(input_output_dir, \"prep.pickle\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The model\n",
    "\n",
    "The model has 3 layers: \n",
    "\n",
    "FC(50) --> Square activation --> FC(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.8.10 64-bit' requires ipykernel package.\n",
      "Run the following command to install 'ipykernel' into the Python environment. \n",
      "Command: '/data/fhe/python/3.8/bin/python3.8 -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "def square(x):\n",
    "    return x ** 2\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(50, input_shape=(input_shape,)))\n",
    "model.add(Activation(activation=square))\n",
    "model.add(Dense(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.8.10 64-bit' requires ipykernel package.\n",
      "Run the following command to install 'ipykernel' into the Python environment. \n",
      "Command: '/data/fhe/python/3.8/bin/python3.8 -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "def sum_squared_error(y_true, y_pred):\n",
    "    y_true = tf.cast(y_pred, tf.float32)\n",
    "    return K.sum(K.square(y_pred - y_true), axis=-1)\n",
    "\n",
    "loss_func = sum_squared_error\n",
    "optimizer_type = SGD(lr=0.01, momentum=0.9)  # Adam\n",
    "\n",
    "model.compile(loss=loss_func,optimizer=optimizer_type,metrics=['accuracy'])\n",
    "model.summary()\n",
    "\n",
    "batch_size = 10\n",
    "epochs = 15\n",
    "\n",
    "model.fit(x_train, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          verbose=2,\n",
    "          validation_data=(x_val, y_val),\n",
    "          shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For later use in HE, we save the trained model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.8.10 64-bit' requires ipykernel package.\n",
      "Run the following command to install 'ipykernel' into the Python environment. \n",
      "Command: '/data/fhe/python/3.8/bin/python3.8 -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "def save_weights(model, index, path):\n",
    "    if not os.path.exists(path):\n",
    "        os.mkdir(path)\n",
    "    fname = os.path.join(path, \"model_epoch_{:0>4}.h5\".format(index))\n",
    "    print(\"Saving weights to: \" + fname)\n",
    "    model.save_weights(fname)\n",
    "    s = model.to_json()\n",
    "\n",
    "    with open(os.path.join(path, f'model_epoch{index}.json'), 'w') as f:\n",
    "        f.write(s)\n",
    "\n",
    "save_weights(model, epochs, path=input_output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.8.10 64-bit' requires ipykernel package.\n",
      "Run the following command to install 'ipykernel' into the Python environment. \n",
      "Command: '/data/fhe/python/3.8/bin/python3.8 -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "\n",
    "print(f'Test loss: {score[0]:.3f}')\n",
    "print(f'Test accuracy:{score[1] * 100:.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using the model for classifying cleartest data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.8.10 64-bit' requires ipykernel package.\n",
      "Run the following command to install 'ipykernel' into the Python environment. \n",
      "Command: '/data/fhe/python/3.8/bin/python3.8 -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "    y_pred = model.predict(x_test)\n",
    "\n",
    "    f, t, thresholds = metrics.roc_curve(y_test, y_pred)\n",
    "    cm = metrics.confusion_matrix(y_test, y_pred)\n",
    "    print(\"Score:\", metrics.auc(f, t))\n",
    "    print(\"Classification report:\")\n",
    "    print(metrics.classification_report(y_test, y_pred))\n",
    "    print(\"Confusion Matrix:\")\n",
    "    print(cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using the model for classifying encrypted data\n",
    "\n",
    "To run the model over encrypted samples with homomorphic encryption (HE), we first load the pyhelayers package and refer it to the directory \"output/\", where we saved the model and the relevant datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.8.10 64-bit' requires ipykernel package.\n",
      "Run the following command to install 'ipykernel' into the Python environment. \n",
      "Command: '/data/fhe/python/3.8/bin/python3.8 -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "import pyhelayers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load test data and labels from the h5 file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.8.10 64-bit' requires ipykernel package.\n",
      "Run the following command to install 'ipykernel' into the Python environment. \n",
      "Command: '/data/fhe/python/3.8/bin/python3.8 -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "with h5py.File(input_output_dir + \"x_test.h5\") as f:\n",
    "    x_test = np.array(f[\"x_test\"])\n",
    "with h5py.File(input_output_dir + \"y_test.h5\") as f:\n",
    "    y_test = np.array(f[\"y_test\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load a plain model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.8.10 64-bit' requires ipykernel package.\n",
      "Run the following command to install 'ipykernel' into the Python environment. \n",
      "Command: '/data/fhe/python/3.8/bin/python3.8 -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "nnp = pyhelayers.NeuralNetPlain()\n",
    "nnp.init_arch_from_json_file(input_output_dir + \"model_epoch15.json\")\n",
    "nnp.init_weights_from_hdf5_file(input_output_dir + \"model_epoch_0015.h5\")\n",
    "print(\"loaded plain model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply automatic optimziations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.8.10 64-bit' requires ipykernel package.\n",
      "Run the following command to install 'ipykernel' into the Python environment. \n",
      "Command: '/data/fhe/python/3.8/bin/python3.8 -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "context = pyhelayers.DefaultContext()\n",
    "optimizer = pyhelayers.HeProfileOptimizer(nnp, context)\n",
    "optimizer.get_requirements().set_batch_size(16)\n",
    "profile = optimizer.get_optimized_profile(False)\n",
    "batch_size = profile.get_batch_size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To reduce the memory requirements of the context, we reduce the number of rotation keys."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.8.10 64-bit' requires ipykernel package.\n",
      "Run the following command to install 'ipykernel' into the Python environment. \n",
      "Command: '/data/fhe/python/3.8/bin/python3.8 -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "pf1=pyhelayers.PublicFunctions()\n",
    "pf1.rotate=pyhelayers.RotationSetType.CUSTOM_ROTATIONS\n",
    "pf1.set_rotation_steps([1,2])\n",
    "pf1.conjugate=False\n",
    "requirements = profile.requirement\n",
    "requirements.public_functions=pf1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Intialize the HE context with the optimized configuration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.8.10 64-bit' requires ipykernel package.\n",
      "Run the following command to install 'ipykernel' into the Python environment. \n",
      "Command: '/data/fhe/python/3.8/bin/python3.8 -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "context.init(profile.requirement)\n",
    "print('HE Context ready. Batch size=',batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print the HE context (w/ keys) size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.8.10 64-bit' requires ipykernel package.\n",
      "Run the following command to install 'ipykernel' into the Python environment. \n",
      "Command: '/data/fhe/python/3.8/bin/python3.8 -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "evalBuf=context.save_to_buffer();\n",
    "print('Size',len(evalBuf)/1024/1024,'MB')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Encrypt the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.8.10 64-bit' requires ipykernel package.\n",
      "Run the following command to install 'ipykernel' into the Python environment. \n",
      "Command: '/data/fhe/python/3.8/bin/python3.8 -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "nn = pyhelayers.NeuralNet(context)\n",
    "nn.encode_encrypt(nnp, profile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use the encrypted model over batches of 16 records at a time. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.8.10 64-bit' requires ipykernel package.\n",
      "Run the following command to install 'ipykernel' into the Python environment. \n",
      "Command: '/data/fhe/python/3.8/bin/python3.8 -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "plain_samples = x_test.take(indices=range(0, batch_size), axis=0)\n",
    "labels = y_test.take(indices=range(0, batch_size), axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Encrypt input samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.8.10 64-bit' requires ipykernel package.\n",
      "Run the following command to install 'ipykernel' into the Python environment. \n",
      "Command: '/data/fhe/python/3.8/bin/python3.8 -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "samples = nn.encode_encrypt_input(plain_samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we perform inference of the 16 samples under encryption "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.8.10 64-bit' requires ipykernel package.\n",
      "Run the following command to install 'ipykernel' into the Python environment. \n",
      "Command: '/data/fhe/python/3.8/bin/python3.8 -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "predictions=nn.predict(samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plaintext results\n",
    "\n",
    "Decrypting the final results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.8.10 64-bit' requires ipykernel package.\n",
      "Run the following command to install 'ipykernel' into the Python environment. \n",
      "Command: '/data/fhe/python/3.8/bin/python3.8 -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "plain_predictions = nn.decrypt_decode_output(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.8.10 64-bit' requires ipykernel package.\n",
      "Run the following command to install 'ipykernel' into the Python environment. \n",
      "Command: '/data/fhe/python/3.8/bin/python3.8 -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "print('\\nclassification results')\n",
    "print('=========================================')\n",
    "for label,pred in zip(labels,plain_predictions):\n",
    "    print('Label:',('Healthy' if label==0 else 'Should talk with a Dr.'),end=', ')\n",
    "    print('Prediction:',('Healthy' if pred[0]<0.5 else 'Should talk with a Dr.'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
