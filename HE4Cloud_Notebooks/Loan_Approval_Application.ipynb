{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "romantic-participant",
   "metadata": {},
   "source": [
    "# Loan risk analysis using thew German Credit Data example\n",
    "\n",
    "This notebook shows an example of training and running a model that classifies people described by a set of attributes as good or bad credit risks.\n",
    "It is based on the <a href=\"https://archive.ics.uci.edu/ml/datasets/statlog+(german+credit+data)\">German Credit Data dataset</a> from the <a href=\"https://archive.ics.uci.edu/\">UCI</a> repository. \n",
    "The target field is an integer either Good (1) or Bad (2), where it is worse to class a customer as good when they are bad (5), than it is to class a customer as bad when they are good (1).\n",
    "\n",
    "The demonstration uses a 6 layer neural network (NN): FC(200) --> Square activation --> FC(100) --> Square activation --> FC(1) --> Square activation\n",
    "\n",
    "The required estimated memory is: model (140MB), input (7.34MB), output (0.26MB), and context (100MB).\n",
    "\n",
    "We start by importing the required source packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eligible-hebrew",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "##### For reproducibility\n",
    "from numpy.random import seed\n",
    "seed(1)\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "#import tensorflow as tf\n",
    "#tf.set_random_seed(seed_value)\n",
    "from keras import backend as K\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "import h5py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "usual-analysis",
   "metadata": {},
   "source": [
    "### Data loading\n",
    "Please refer to the dataset <a href=\"https://archive.ics.uci.edu/ml/datasets/statlog+(german+credit+data)\">documentation</a> for the complete list of attributes and their description."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "revised-facial",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>checking</th>\n",
       "      <th>duration</th>\n",
       "      <th>credit-hist</th>\n",
       "      <th>purpose</th>\n",
       "      <th>credit-amount</th>\n",
       "      <th>savings-account</th>\n",
       "      <th>employment-duration</th>\n",
       "      <th>installment-income-ratio</th>\n",
       "      <th>debtors-guarantors</th>\n",
       "      <th>residence-since</th>\n",
       "      <th>property</th>\n",
       "      <th>age</th>\n",
       "      <th>installment-plans</th>\n",
       "      <th>housing</th>\n",
       "      <th>num-existing-credits</th>\n",
       "      <th>job</th>\n",
       "      <th>num-liable</th>\n",
       "      <th>telephone</th>\n",
       "      <th>foreign-worker</th>\n",
       "      <th>is_good</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A11</td>\n",
       "      <td>17</td>\n",
       "      <td>A32</td>\n",
       "      <td>A43</td>\n",
       "      <td>595</td>\n",
       "      <td>A61</td>\n",
       "      <td>A73</td>\n",
       "      <td>3</td>\n",
       "      <td>A103</td>\n",
       "      <td>4</td>\n",
       "      <td>A121</td>\n",
       "      <td>23</td>\n",
       "      <td>A143</td>\n",
       "      <td>A152</td>\n",
       "      <td>1</td>\n",
       "      <td>A173</td>\n",
       "      <td>1</td>\n",
       "      <td>A191</td>\n",
       "      <td>A201</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A12</td>\n",
       "      <td>16</td>\n",
       "      <td>A34</td>\n",
       "      <td>A43</td>\n",
       "      <td>284</td>\n",
       "      <td>A62</td>\n",
       "      <td>A74</td>\n",
       "      <td>4</td>\n",
       "      <td>A101</td>\n",
       "      <td>4</td>\n",
       "      <td>A121</td>\n",
       "      <td>20</td>\n",
       "      <td>A143</td>\n",
       "      <td>A152</td>\n",
       "      <td>1</td>\n",
       "      <td>A174</td>\n",
       "      <td>1</td>\n",
       "      <td>A191</td>\n",
       "      <td>A201</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A11</td>\n",
       "      <td>5</td>\n",
       "      <td>A32</td>\n",
       "      <td>A43</td>\n",
       "      <td>267</td>\n",
       "      <td>A61</td>\n",
       "      <td>A75</td>\n",
       "      <td>4</td>\n",
       "      <td>A101</td>\n",
       "      <td>4</td>\n",
       "      <td>A123</td>\n",
       "      <td>26</td>\n",
       "      <td>A143</td>\n",
       "      <td>A152</td>\n",
       "      <td>1</td>\n",
       "      <td>A173</td>\n",
       "      <td>1</td>\n",
       "      <td>A192</td>\n",
       "      <td>A201</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A14</td>\n",
       "      <td>5</td>\n",
       "      <td>A34</td>\n",
       "      <td>A41</td>\n",
       "      <td>1194</td>\n",
       "      <td>A61</td>\n",
       "      <td>A75</td>\n",
       "      <td>1</td>\n",
       "      <td>A101</td>\n",
       "      <td>4</td>\n",
       "      <td>A123</td>\n",
       "      <td>62</td>\n",
       "      <td>A143</td>\n",
       "      <td>A152</td>\n",
       "      <td>4</td>\n",
       "      <td>A173</td>\n",
       "      <td>1</td>\n",
       "      <td>A191</td>\n",
       "      <td>A201</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A14</td>\n",
       "      <td>5</td>\n",
       "      <td>A32</td>\n",
       "      <td>A46</td>\n",
       "      <td>924</td>\n",
       "      <td>A61</td>\n",
       "      <td>A73</td>\n",
       "      <td>1</td>\n",
       "      <td>A101</td>\n",
       "      <td>1</td>\n",
       "      <td>A123</td>\n",
       "      <td>63</td>\n",
       "      <td>A142</td>\n",
       "      <td>A152</td>\n",
       "      <td>1</td>\n",
       "      <td>A173</td>\n",
       "      <td>1</td>\n",
       "      <td>A191</td>\n",
       "      <td>A201</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  checking  duration credit-hist purpose  credit-amount savings-account  \\\n",
       "0      A11        17         A32     A43            595             A61   \n",
       "1      A12        16         A34     A43            284             A62   \n",
       "2      A11         5         A32     A43            267             A61   \n",
       "3      A14         5         A34     A41           1194             A61   \n",
       "4      A14         5         A32     A46            924             A61   \n",
       "\n",
       "  employment-duration  installment-income-ratio debtors-guarantors  \\\n",
       "0                 A73                         3               A103   \n",
       "1                 A74                         4               A101   \n",
       "2                 A75                         4               A101   \n",
       "3                 A75                         1               A101   \n",
       "4                 A73                         1               A101   \n",
       "\n",
       "   residence-since property  age installment-plans housing  \\\n",
       "0                4     A121   23              A143    A152   \n",
       "1                4     A121   20              A143    A152   \n",
       "2                4     A123   26              A143    A152   \n",
       "3                4     A123   62              A143    A152   \n",
       "4                1     A123   63              A142    A152   \n",
       "\n",
       "   num-existing-credits   job  num-liable telephone foreign-worker  is_good  \n",
       "0                     1  A173           1      A191           A201        1  \n",
       "1                     1  A174           1      A191           A201        2  \n",
       "2                     1  A173           1      A192           A201        1  \n",
       "3                     4  A173           1      A191           A201        1  \n",
       "4                     1  A173           1      A191           A201        2  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('data/german_credit/german.data.filtered.csv', index_col=0, sep=\",\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "decimal-commander",
   "metadata": {},
   "source": [
    "### Data preprocessing\n",
    "\n",
    "We first convert the categorial features (in the table below) to indicator vectors. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "professional-terrain",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data shape: (100000, 59)\n"
     ]
    }
   ],
   "source": [
    "df['telephone'] = df['telephone'].replace(['A191', 'A192'], [0, 1])\n",
    "df['foreign-worker'] = df['foreign-worker'].replace(['A201', 'A202'], [1, 0])\n",
    "df['is_good'] = df['is_good'].replace([1, 2], [1, 0])\n",
    "\n",
    "cat_features_list = ['checking', 'credit-hist', 'purpose', 'savings-account', 'employment-duration',\n",
    "                      'debtors-guarantors', 'property', 'installment-plans', 'housing',\n",
    "                     'num-existing-credits','job' ]\n",
    "\n",
    "for f in cat_features_list:\n",
    "    dummy = pd.get_dummies(df[f], prefix=f.strip())\n",
    "    df = pd.concat([df, dummy], axis='columns')\n",
    "\n",
    "final = df.drop(cat_features_list,axis=1)\n",
    "print(f'data shape: {final.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "revolutionary-export",
   "metadata": {},
   "source": [
    "Subsequently, we split every row into its target value (y) and predicates (X)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "quick-hebrew",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>duration</th>\n",
       "      <th>credit-amount</th>\n",
       "      <th>installment-income-ratio</th>\n",
       "      <th>residence-since</th>\n",
       "      <th>age</th>\n",
       "      <th>num-liable</th>\n",
       "      <th>telephone</th>\n",
       "      <th>foreign-worker</th>\n",
       "      <th>checking_A11</th>\n",
       "      <th>checking_A12</th>\n",
       "      <th>...</th>\n",
       "      <th>housing_A152</th>\n",
       "      <th>housing_A153</th>\n",
       "      <th>num-existing-credits_1</th>\n",
       "      <th>num-existing-credits_2</th>\n",
       "      <th>num-existing-credits_3</th>\n",
       "      <th>num-existing-credits_4</th>\n",
       "      <th>job_A171</th>\n",
       "      <th>job_A172</th>\n",
       "      <th>job_A173</th>\n",
       "      <th>job_A174</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17</td>\n",
       "      <td>595</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>23</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>16</td>\n",
       "      <td>284</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>267</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>26</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>1194</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>62</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>924</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>63</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 58 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   duration  credit-amount  installment-income-ratio  residence-since  age  \\\n",
       "0        17            595                         3                4   23   \n",
       "1        16            284                         4                4   20   \n",
       "2         5            267                         4                4   26   \n",
       "3         5           1194                         1                4   62   \n",
       "4         5            924                         1                1   63   \n",
       "\n",
       "   num-liable  telephone  foreign-worker  checking_A11  checking_A12  ...  \\\n",
       "0           1          0               1             1             0  ...   \n",
       "1           1          0               1             0             1  ...   \n",
       "2           1          1               1             1             0  ...   \n",
       "3           1          0               1             0             0  ...   \n",
       "4           1          0               1             0             0  ...   \n",
       "\n",
       "   housing_A152  housing_A153  num-existing-credits_1  num-existing-credits_2  \\\n",
       "0             1             0                       1                       0   \n",
       "1             1             0                       1                       0   \n",
       "2             1             0                       1                       0   \n",
       "3             1             0                       0                       0   \n",
       "4             1             0                       1                       0   \n",
       "\n",
       "   num-existing-credits_3  num-existing-credits_4  job_A171  job_A172  \\\n",
       "0                       0                       0         0         0   \n",
       "1                       0                       0         0         0   \n",
       "2                       0                       0         0         0   \n",
       "3                       0                       1         0         0   \n",
       "4                       0                       0         0         0   \n",
       "\n",
       "   job_A173  job_A174  \n",
       "0         1         0  \n",
       "1         0         1  \n",
       "2         1         0  \n",
       "3         1         0  \n",
       "4         1         0  \n",
       "\n",
       "[5 rows x 58 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = final.drop(['is_good'], axis=1)\n",
    "y = final['is_good']\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "embedded-cornwall",
   "metadata": {},
   "source": [
    "We split the dataset into the training (x_train, y_train) and test (x_test, y_test) sets and scale their features. Subsequently, we split the test set into test and validation sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "multiple-scene",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(X, y ,test_size=0.2, random_state=5, stratify=y)\n",
    "\n",
    "feature_scaler = MinMaxScaler()\n",
    "x_train = feature_scaler.fit_transform(x_train)\n",
    "x_test = feature_scaler.transform(x_test)\n",
    "\n",
    "x_test, x_val, y_test, y_val = train_test_split(x_test, y_test, test_size=4096, random_state=5, stratify=y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daily-synthetic",
   "metadata": {},
   "source": [
    "For later use in HE, we save the different preprocessed datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "center-virginia",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving x_test of shape (15904, 58) in outputs/x_test.h5\n",
      "Saving y_test of shape (15904,) in outputs/x_test.h5\n",
      "Saving x_train of shape (80000, 58) in outputs/x_train.h5\n",
      "Saving y_train of shape (80000,) in outputs/x_train.h5\n",
      "Saving x_val of shape (4096, 58) in outputs/x_val.h5\n",
      "Saving y_val of shape (4096,) in outputs/x_val.h5\n"
     ]
    }
   ],
   "source": [
    "def save_data_set(x, y, data_type, path, s=''):\n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path)\n",
    "    fname=os.path.join(path, f'x_{data_type}{s}.h5')\n",
    "    print(\"Saving x_{} of shape {} in {}\".format(data_type, x.shape, fname))\n",
    "    xf = h5py.File(fname, 'w')\n",
    "    xf.create_dataset('x_{}'.format(data_type), data=x)\n",
    "    xf.close()\n",
    "\n",
    "    print(\"Saving y_{} of shape {} in {}\".format(data_type, y.shape, fname))\n",
    "    yf = h5py.File(os.path.join(path, f'y_{data_type}{s}.h5'), 'w')\n",
    "    yf.create_dataset(f'y_{data_type}', data=y)\n",
    "    yf.close()\n",
    "\n",
    "input_output_dir = \"outputs/\"\n",
    "\n",
    "save_data_set(x_test, y_test, data_type='test', path=input_output_dir)\n",
    "save_data_set(x_train, y_train, data_type='train', path=input_output_dir)\n",
    "save_data_set(x_val, y_val, data_type='val', path=input_output_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "appropriate-button",
   "metadata": {},
   "source": [
    "### The model\n",
    "\n",
    "The model has 6 layers: \n",
    "\n",
    "FC(200) --> Square activation --> FC(100) --> Square activation --> FC(1) --> Square activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "southwest-delivery",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 200)               11800     \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 100)               20100     \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 101       \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 32,001\n",
      "Trainable params: 32,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def square(x):\n",
    "    return x ** 2\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(200, input_shape=(x_train.shape[1],)))\n",
    "model.add(Activation(activation=square))\n",
    "model.add(Dense(100))\n",
    "model.add(Activation(activation=square))\n",
    "model.add(Dense(1))\n",
    "model.add(Activation(activation=square))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "happy-truth",
   "metadata": {},
   "source": [
    "#### Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "pressing-alliance",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_grad.py:1205: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "Train on 80000 samples, validate on 4096 samples\n",
      "Epoch 1/5\n",
      " - 1s - loss: 0.1584 - accuracy: 0.7812 - val_loss: 0.1313 - val_accuracy: 0.8169\n",
      "Epoch 2/5\n",
      " - 1s - loss: 0.1271 - accuracy: 0.8235 - val_loss: 0.1292 - val_accuracy: 0.8242\n",
      "Epoch 3/5\n",
      " - 1s - loss: 0.1246 - accuracy: 0.8269 - val_loss: 0.1268 - val_accuracy: 0.8240\n",
      "Epoch 4/5\n",
      " - 1s - loss: 0.1233 - accuracy: 0.8288 - val_loss: 0.1270 - val_accuracy: 0.8218\n",
      "Epoch 5/5\n",
      " - 1s - loss: 0.1216 - accuracy: 0.8300 - val_loss: 0.1256 - val_accuracy: 0.8269\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x7f18caecae80>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def sum_squared_error(y_true, y_pred):\n",
    "    return K.sum(K.square(y_pred - y_true), axis=-1)\n",
    "\n",
    "batch_size = 400\n",
    "epochs = 5\n",
    "learning_rate = 0.001\n",
    "\n",
    "model.compile(loss=sum_squared_error,  # losses.BinaryCrossentropy(from_logits=True), =>for v2\n",
    "              optimizer=Adam(lr=learning_rate),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train, y_train,\n",
    "              batch_size=batch_size,\n",
    "              epochs=epochs,\n",
    "              verbose=2,\n",
    "              validation_data=(x_val, y_val),\n",
    "              shuffle=True,\n",
    "              )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "starting-elder",
   "metadata": {},
   "source": [
    "For later use in HE, we save the trained model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "sweet-button",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving weights to: outputs/model_epoch_0005.h5\n"
     ]
    }
   ],
   "source": [
    "def save_weights(model, index, path):\n",
    "    if not os.path.exists(path):\n",
    "        os.mkdir(path)\n",
    "    fname = os.path.join(path, \"model_epoch_{:0>4}.h5\".format(index))\n",
    "    print(\"Saving weights to: \" + fname)\n",
    "    model.save_weights(fname)\n",
    "    s = model.to_json()\n",
    "\n",
    "    with open(os.path.join(path, f'model_epoch{index}.json'), 'w') as f:\n",
    "        f.write(s)\n",
    "\n",
    "save_weights(model, epochs, path=input_output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "patient-developer",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.126\n",
      "Test accuracy:82.438\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "\n",
    "print(f'Test loss: {score[0]:.3f}')\n",
    "print(f'Test accuracy:{score[1] * 100:.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "described-crowd",
   "metadata": {},
   "source": [
    "#### Using the model for classifying cleartest data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "small-jacket",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: 0.7768682362551952\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.66      0.69      4782\n",
      "           1       0.86      0.90      0.88     11122\n",
      "\n",
      "    accuracy                           0.82     15904\n",
      "   macro avg       0.80      0.78      0.78     15904\n",
      "weighted avg       0.82      0.82      0.82     15904\n",
      "\n",
      "Confusion Matrix:\n",
      "[[3145 1637]\n",
      " [1156 9966]]\n"
     ]
    }
   ],
   "source": [
    "    y_pred = model.predict_classes(x_test)\n",
    "\n",
    "    f, t, thresholds = metrics.roc_curve(y_test, y_pred)\n",
    "    cm = metrics.confusion_matrix(y_test, y_pred)\n",
    "    print(\"Score:\", metrics.auc(f, t))\n",
    "    print(\"Classification report:\")\n",
    "    print(metrics.classification_report(y_test, y_pred))\n",
    "    print(\"Confusion Matrix:\")\n",
    "    print(cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "criminal-courtesy",
   "metadata": {},
   "source": [
    "### Using the model for classifying encrypted data\n",
    "\n",
    "To run the model over encrypted samples with homomorphic encryption (HE), we first load the pyhelayers package and refer it to the directory \"output/\", where we saved the model and the relevant datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "passing-dayton",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyhelayers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "specified-natural",
   "metadata": {},
   "source": [
    "Load test data and labels from the h5 file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "living-thunder",
   "metadata": {},
   "outputs": [],
   "source": [
    "with h5py.File(input_output_dir + \"x_test.h5\") as f:\n",
    "    x_test = np.array(f[\"x_test\"])\n",
    "with h5py.File(input_output_dir + \"y_test.h5\") as f:\n",
    "    y_test = np.array(f[\"y_test\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "linear-password",
   "metadata": {},
   "source": [
    "Load a plain model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "complimentary-thing",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded plain model\n"
     ]
    }
   ],
   "source": [
    "nnp = pyhelayers.NeuralNetPlain()\n",
    "nnp.init_arch_from_json_file(input_output_dir + \"model_epoch5.json\")\n",
    "nnp.init_weights_from_hdf5_file(input_output_dir + \"model_epoch_0005.h5\")\n",
    "print(\"loaded plain model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "potential-domain",
   "metadata": {},
   "source": [
    "Apply automatic optimziations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "characteristic-michigan",
   "metadata": {},
   "outputs": [],
   "source": [
    "context = pyhelayers.DefaultContext()\n",
    "optimizer = pyhelayers.HeProfileOptimizer(nnp, context)\n",
    "optimizer.get_requirements().set_batch_size(16)\n",
    "profile = optimizer.get_optimized_profile(False)\n",
    "batch_size = profile.get_batch_size()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abstract-champion",
   "metadata": {},
   "source": [
    "To reduce the memory requirements of the context, we reduce the number of rotation keys."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "entire-south",
   "metadata": {},
   "outputs": [],
   "source": [
    "pf1=pyhelayers.PublicFunctions()\n",
    "pf1.rotate=pyhelayers.RotationSetType.CUSTOM_ROTATIONS\n",
    "pf1.set_rotation_steps([1,2,4,8,16])\n",
    "pf1.conjugate=True\n",
    "requirements = profile.requirement\n",
    "requirements.public_functions=pf1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "productive-electron",
   "metadata": {},
   "source": [
    "Intialize the HE context with the optimized configuration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "mexican-basis",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HE Context ready. Batch size= 16\n"
     ]
    }
   ],
   "source": [
    "context.init(profile.requirement)\n",
    "print('HE Context ready. Batch size=',batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "romance-begin",
   "metadata": {},
   "source": [
    "Print the HE context (w/ keys) size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "indoor-driving",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size 100.13051319122314 MB\n"
     ]
    }
   ],
   "source": [
    "evalBuf=context.save_to_buffer();\n",
    "print('Size',len(evalBuf)/1024/1024,'MB')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "amazing-internship",
   "metadata": {},
   "source": [
    "#### Encrypt the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "killing-optimum",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Object (detailed printing not implemented yet)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn = pyhelayers.NeuralNet(context)\n",
    "nn.encode_encrypt(nnp, profile)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "danish-permission",
   "metadata": {},
   "source": [
    "We use the encrypted model over batches of 16 records at a time. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "romance-playback",
   "metadata": {},
   "outputs": [],
   "source": [
    "plain_samples = x_test.take(indices=range(0, 16), axis=0)\n",
    "labels = y_test.take(indices=range(0, 16), axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "prime-disability",
   "metadata": {},
   "source": [
    "Encrypt input samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "located-pierre",
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = nn.encode_encrypt_input(plain_samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "random-battle",
   "metadata": {},
   "source": [
    "Now we perform inference of the 16 samples under encryption "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "medium-shoulder",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions=nn.predict(samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "lasting-scale",
   "metadata": {},
   "source": [
    "### Plaintext results\n",
    "\n",
    "Decrypting the final results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "adjacent-manhattan",
   "metadata": {},
   "outputs": [],
   "source": [
    "plain_predictions = nn.decrypt_decode_output(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "placed-metropolitan",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "classification results\n",
      "=========================================\n",
      "Label: Good, Prediction: Good.\n",
      "Label: Good, Prediction: Good.\n",
      "Label: Good, Prediction: Bad\n",
      "Label: Bad., Prediction: Bad\n",
      "Label: Good, Prediction: Good.\n",
      "Label: Good, Prediction: Good.\n",
      "Label: Bad., Prediction: Bad\n",
      "Label: Good, Prediction: Good.\n",
      "Label: Good, Prediction: Good.\n",
      "Label: Good, Prediction: Good.\n",
      "Label: Good, Prediction: Good.\n",
      "Label: Good, Prediction: Bad\n",
      "Label: Good, Prediction: Good.\n",
      "Label: Good, Prediction: Good.\n",
      "Label: Bad., Prediction: Bad\n",
      "Label: Good, Prediction: Good.\n"
     ]
    }
   ],
   "source": [
    "print('\\nclassification results')\n",
    "print('=========================================')\n",
    "for label,pred in zip(labels,plain_predictions):\n",
    "    print('Label:',('Good' if label==1 else 'Bad.'),end=', ')\n",
    "    print('Prediction:',('Bad' if pred[0]<0.5 else 'Good.'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecological-liberty",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
